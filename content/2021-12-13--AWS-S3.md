---
date: 2021-12-13
draft: false
thumbnail: /post-images/aws-s3.png
title: AWS - S3
extract: Notes for S3
categories:
    - AWS
tags:
    - blog
    - AWS
--- 


### Table of Contents

- [What is S3?](#what-is-s3)
- [S3 Basics](#s3-basics)
- [S3 Objects](#s3-objects)
  - [Object Key](#object-key)
  - [Object Value](#object-value)
  - [Object Metadata](#object-metadata)
  - [Object Version ID](#object-version-id)
- [S3 Buckets](#s3-buckets)
- [S3 Versioning](#s3-versioning)
  - [Versioning workflows](#versioning-workflows)
  - [Delete Markers](#delete-markers)
- [S3 Storage Classes](#s3-storage-classes)
  - [S3 Standard](#s3-standard)
  - [Reduced Redundancy](#reduced-redundancy)
  - [S3 IA Classes](#s3-ia-classes)
    - [S3 Standard IA](#s3-standard-ia)
    - [S3 One Zone IA](#s3-one-zone-ia)
  - [S3 Glacier IR](#s3-glacier-ir)
  - [S3 Glacier FR](#s3-glacier-fr)
  - [S3 Glacier Deep Archive](#s3-glacier-deep-archive)
- [Lifecycle Management](#lifecycle-management)
- [Storage Classes Comparison](#storage-classes-comparison)
- [Securing your data](#securing-your-data)
- [Consistency Model](#consistency-model)
- [Hosting a Static Website](#hosting-a-static-website)
  - [Endpoints](#endpoints)
  - [Adding a DNS CNAME](#adding-a-dns-cname)
  - [Enabling website hosting](#enabling-website-hosting)
    - [Configuring an index document](#configuring-an-index-document)
    - [Configuring a custom error document](#configuring-a-custom-error-document)
    - [Setting permissions for website access](#setting-permissions-for-website-access)




## What is S3?
Simple Storage Service, or S3, provides object storage in the cloud. It is a durable and highly scalable service. S3 is object based storage: meaning it manages data as objects rather than file system. S3 is a key value store where key is the name you give your object and value is the object itself. You can upload any file type to S3 (image, text, videos, HTML files etc). You however, cannot run OSs or DBs on S3! You store your static files in S3. 

## S3 Basics
You can store unlimited number of objects in S3. Objects can be from 0B to 5TB in size. Files are stored in a bucket. 

![S3-Basics](./images/aws/s3-basics.png)[Image Credit - Acloud guru](https://acloudguru.com/)

## S3 Objects
An S3 [object](https://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingObjects.html) is comprised of a key, a value, a versionId and metadata. Let's take a look at some of these in more detail:

### Object Key
The name that you assign to an object. You use the object key to retrieve the object. The object key (or key name) uniquely identifies the object in an Amazon S3 bucket. 

### Object Value

Value is the actual content that you are storing. An object value can be any sequence of bytes. Objects can range in size from zero to 5 TB. If your object size is >= 5MB, it is suggested to use multi-part upload. The multipart upload API is designed to improve the upload experience for larger objects. You can upload an object in parts. These object parts can be uploaded independently, in any order, and in parallel. You can use a multipart upload for objects from 5 MB to 5 TB in size. 

### Object Metadata
Along with the object data (bytes that make your object), there also exists object metadata. The metadata is a set of name-value pairs that describe the object. These pairs include some default metadata, such as the date last modified, and standard HTTP metadata, such as Content-Type. You can also specify custom metadata at the time that the object is stored. 

There are two kinds of metadata in Amazon S3: system-defined metadata and user-defined metadata. System metadata information include the following:
- Date
- Content-Length	
- Content-Type	
- Last-Modified	
- x-amz-server-side-encryption
- x-amz-version-id	
- x-amz-delete-marker	
- x-amz-storage-class	
- x-amz-website-redirect-location	

and more! 

User-defined metadata can be defined when uploading an object. You provide this optional information as a name-value (key-value) pair when you send a PUT or POST request to create the object. When you upload objects using the REST API, the optional user-defined metadata names must begin with "x-amz-meta-" to distinguish them from other HTTP headers. When you retrieve the object using the REST API, this prefix is returned. 

More info on metadata [here](https://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingMetadata.html)

### Object Version ID
Version ID allows you to store multiple versions of the same object. See versioning section below. 

## S3 Buckets
A bucket is a container for objects stored in Amazon S3. You can store any number of objects in a bucket and can have up to 100 buckets in your account. To request an increase, visit the Service Quotas Console. Here're a few properties related to our S3 buckets:

- **Universal Namespace**

An Amazon S3 bucket name is globally unique, and the namespace is shared by all AWS accounts. This means that after a bucket is created, the name of that bucket cannot be used by another AWS account in any AWS Region until the bucket is deleted. You should not depend on specific bucket naming conventions for availability or security verification purposes. Amazon S3 creates buckets in a Region that you specify. To optimize latency, minimize costs, or address regulatory requirements, choose any AWS Region that is geographically close to you.  

- **Bucket URLs**

Each bucket that you create will have a URL associated with it. The URL will follow this convention:

`https://<bucket-name>.s3.<Region>.amazonaws.com/<key-name>`

For example, if the object named photos/puppy.jpg is stored in the DOC-EXAMPLE-BUCKET bucket in the US West (Oregon) Region, then it is addressable using the URL `https://DOC-EXAMPLE-BUCKET.s3.us-west-2.amazonaws.com/photos/puppy.jpg`. When you create a bucket, you enter a bucket name and choose the AWS Region where the bucket will reside. After you create a bucket, you cannot change the name of the bucket or its Region. Bucket names must follow the bucket naming rules. 

## S3 Versioning
You can use S3 Versioning to keep multiple variants of an object in the same bucket. With S3 Versioning, you can preserve, retrieve, and restore every version of every object stored in your buckets. You can easily recover from both unintended user actions and application failures. **Versioning helps you recover accidental overwrites and deletes along with MFA.** 

It is recommend to use versioning as a best practice to recover objects from being deleted or overwritten by mistake. For example, if you delete an object, Amazon S3 inserts a delete marker instead of removing the object permanently. The delete marker becomes the current object version. If you overwrite an object, it results in a new object version in the bucket. You can always restore the previous version. **By default, S3 Versioning is disabled on buckets, and you must explicitly enable it.**

Buckets can be in one of three states: Unversioned (the default), versioning-enabled or versioning-suspended. You enable and suspend versioning at the bucket level. After you version-enable a bucket, it can never return to an unversioned state. But you can suspend versioning on that bucket.  When you enable versioning in a bucket, all new objects are versioned and given a unique version ID. Objects that already existed in the bucket at the time versioning was enabled will thereafter always be versioned and given a unique version ID when they are modified by future requests. 

Let's say you uploaded a file and then uploaded a 2nd version with some changes. With `Show Versions` enabled, you'll see this in the bucket:

![Bucket-Versioning](./images/aws/bucket-versioning.png)

You'll be able to see the old version (last in the list above) but won't be able to access it. You'll get an access denied if you tried. That's because the old version is not public.

### Versioning workflows
When you PUT an object in a versioning-enabled bucket, the noncurrent version is not overwritten. The following figure shows that when a new version of photo.gif is PUT into a bucket that already contains an object with the same name, the original object (ID = 111111) remains in the bucket, Amazon S3 generates a new version ID (121212), and adds the newer version to the bucket.

![Versioning-PUT](./images/aws/versioning-put.png)[Image-Credit](https://docs.aws.amazon.com/AmazonS3/latest/userguide/versioning-workflows.html)


This functionality prevents you from accidentally overwriting or deleting objects and gives you the opportunity to retrieve a previous version of an object.

When you DELETE an object, all versions remain in the bucket and Amazon S3 inserts a delete marker, as shown in the following figure.

![Versioning-Delete](./images/aws/versioning-delete.png)[Image-Credit](https://docs.aws.amazon.com/AmazonS3/latest/userguide/versioning-workflows.html)

The delete marker becomes the current version of the object. By default, GET requests retrieve the most recently stored version. Performing a simple GET Object request when the current version is a delete marker returns a 404 Not Found error, as shown in the following figure.

![Deleted-Get](./images/aws/versioning-deleted-get.png)[Image-Credit](https://docs.aws.amazon.com/AmazonS3/latest/userguide/versioning-workflows.html)

You can add more security by configuring a bucket to enable MFA (multi-factor authentication) delete. When you do, the bucket owner must include two forms of authentication in any request to delete a version or change the versioning state of the bucket.

### Delete Markers
Let's go ahead and delete `index.html`. It disappears from the list but if you click on `Show Versions` you notice that it is not actually gone:

![Delete-Marker](./images/aws/delete-marker.png)

Now what if I want to bring back this deleted file? Just delete the delete marker! Which is delete the `index.html` file again. 

If you delete an object, instead of removing it permanently, Amazon S3 inserts a delete marker, which becomes the current object version. You can then restore the previous version.

## S3 Storage Classes

### S3 Standard
The default storage class. If you don't specify the storage class when you upload an object, Amazon S3 assigns the S3 Standard storage class.

Properties:
  - Data is stored redundantly across multiple devices in multiple facilities ( >= 3AZs).
  - 99.99% availability
  - 99.999999999% durability
  - Designed for frequent access
  - Suitable for websites, content distribution, mobile and gaming apps, big data analytics etc
  
### Reduced Redundancy
The Reduced Redundancy Storage (RRS) storage class is designed for noncritical, reproducible data that can be stored with less redundancy than the S3 Standard storage class.

### S3 IA Classes
The S3 Standard-IA and S3 One Zone-IA storage classes are designed for long-lived and infrequently accessed data. (IA stands for infrequent access.) S3 Standard-IA and S3 One Zone-IA objects are available for millisecond access (similar to the S3 Standard storage class). Amazon S3 charges a retrieval fee for these objects, so they are most suitable for infrequently accessed data. 

You might choose the S3 Standard-IA and S3 One Zone-IA storage classes to do the following:
 - For storing backups.
 - For older data that is accessed infrequently, but that still requires millisecond access. For example, when you upload data, you might choose the S3 Standard storage class, and use lifecycle configuration to tell Amazon S3 to transition the objects to the S3 Standard-IA or S3 One Zone-IA class.

The S3 Standard-IA and S3 One Zone-IA storage classes are suitable for objects larger than 128 KB that you plan to store for at least 30 days. If an object is less than 128 KB, Amazon S3 charges you for 128 KB. If you delete an object before the end of the 30-day minimum storage duration period, you are charged for 30 days.

#### S3 Standard IA
Amazon S3 stores the object data redundantly across multiple geographically separated Availability Zones (similar to the S3 Standard storage class). S3 Standard-IA objects are resilient to the loss of an Availability Zone. This storage class offers greater availability and resiliency than the S3 One Zone-IA class.

**Use for your primary or only copy of data that can't be re-created.**

#### S3 One Zone IA
Amazon S3 stores the object data in only one Availability Zone, which makes it less expensive than S3 Standard-IA. However, the data is not resilient to the physical loss of the Availability Zone resulting from disasters, such as earthquakes and floods. The S3 One Zone-IA storage class is as durable as Standard-IA, but it is less available and less resilient.

**Use if you can re-create the data if the Availability Zone fails, and for object replicas when setting S3 Cross-Region Replication (CRR).**

### S3 Glacier IR
Use for archiving data that is rarely accessed and requires milliseconds retrieval. Data stored in the S3 Glacier Instant Retrieval storage class offers a cost savings compared to the S3 Standard-IA storage class, with the same latency and throughput performance as the S3 Standard-IA storage class. S3 Glacier Instant Retrieval has higher data access costs than S3 Standard-IA. 

### S3 Glacier FR
Use for archives where portions of the data might need to be retrieved in minutes. Data stored in the S3 Glacier Flexible Retrieval storage class has a minimum storage duration period of 90 days and can be accessed in as little as 1-5 minutes using expedited retrieval. If you have deleted, overwritten, or transitioned to a different storage class an object before the 90-day minimum, you are charged for 90 days. 

### S3 Glacier Deep Archive
Use for archiving data that rarely needs to be accessed. Data stored in the S3 Glacier Deep Archive storage class has a minimum storage duration period of 180 days and a default retrieval time of 12 hours. S3 Glacier Deep Archive is the lowest cost storage option in AWS. Storage costs for S3 Glacier Deep Archive are less expensive than using the S3 Glacier Flexible Retrieval storage class. You can reduce S3 Glacier Deep Archive retrieval costs by using bulk retrieval, which returns data within 48 hours.

## Lifecycle Management
There are methods in place to move your data from different S3 tiers.

## Storage Classes Comparison
| Storage class	      | Designed for	  | Availability | Min storage duration | Min billable object size | Other considerations |
| ----------- | -----------  | ----------- | ----------- | ----------- | ----------- |
| **Standard**      | Frequently accessed data (more than once a month) with millsecond access              | 99.99%         | None       | None       | None       |
| **Standard-IA**   | Long-lived, infrequently accessed data (once a month) with millisecond access                | 99.9%           | 30 days        | 128KB        | Per GB retrieval fees apply        |
| **Intelligent-Tiering**   | Data with unknown, changing, or unpredictable access patterns                | 99.9%           | None        | None        | Monitoring and automation fees per object apply. No retrieval fees.        |
| **One Zone-IA**   | Recreatable, infrequently accessed data (once a month) with millisecond access                | 99.5%        | 30 days        | 128KB        | Per GB retrieval fees apply. Not resilient to the loss of the Availability Zone.        |
| **Glacier Instant Retrieval**   | Long-lived, archive data accessed once a quarter with millisecond access                | 99.9%           | 90 days        | 128 KB        | Per GB retrieval fees apply.        |
| **Glacier Flexible Retrieval**   | Long-lived archive data accessed once a year with retrieval times of minutes to hours                | 99.99% (after you restore objects)           | 90 days        | 40 KB        | Per GB retrieval fees apply. You must first restore archived objects before you can access them.         |
| **Glacier Deep Archive**   | Long-lived archive data accessed less than once a year with retrieval times of hours                | 99.99% (after you restore objects)           | 180 days        | 40 KB        | Per GB retrieval fees apply. You must first restore archived objects before you can access them.        |



* All of the classes above have a durability of 11 9s: 99.999999999%
* All classes above are replicated across 3 AZs EXCEPT for obviously One Zone-IA that is replicated in 1 AZ.
* All of the storage classes except for S3 One Zone-IA are designed to be resilient to the physical loss of an Availability Zone resulting from disasters. In addition to the performance requirements of your application scenario, consider costs.

## Securing your data
- **Server side encryption**:
You can set default encryption on a bucket to encrypt all new objects when they are stored in the bucket. 

- **ACLs**:
Define which AWS accounts or groups are granted access and the type of access on your buckets. You can attach S3 ACLs to individul objects within a bucket. Much more fine grained access policies! 

- **Bucket Policies**:
S3 bucket policies that specify what action are allowed or denied (example user A can PUT but not DELETE). Bucket policies are obviously bucket wide. These are IAM policies for S3 buckets. This is more general as compared to ACLs. 

Here's how bucket policies compare to ACLs:

![ALC-vs-Bucket-Policy](./images/aws/acl-vs-bucket-policy.png)[Image Credit - Acloud guru](https://acloudguru.com/)

- **Block Public Access**

This setting blocks public access of your bucket. This is turned on by default. This will make your bucket private. If you try and visit the URL for the uploaded object, you'll see this:

```xml
<Error>
  <Code>AccessDenied</Code>
  <Message>Access Denied</Message>
  <RequestId>G7FM3575JGCWJ9G0</RequestId>
  <HostId>uJHMgzPTlEBCvZjMO0g8+YCBTx21Kc3yAofsC+vRZ2kclsSQDgRf8RqqZyAAMNUypxDjXqZ6tu0=</HostId>
</Error>
```

If you try and make it public, you'll get an error since you've blocked public access at the bucket level. To objects public, you need to make your bucket public first and then make objects public. 

## Consistency Model

S3 has **strong read after write consistency** meaning that after a successful write of a new object (PUT, UPDATE or DELETE), any subsequent read requests immediately receive the latest version of the object. 

S3 is strongly consistent for LIST operations

## Hosting a Static Website
You can use Amazon S3 to host a **static** website. On a static website, individual webpages include static content. They might also contain client-side scripts. By contrast, a dynamic website relies on server-side processing, including server-side scripts such as PHP, JSP, or ASP.NET. Amazon S3 does not support server-side scripting, but AWS has other resources for hosting dynamic websites. 

To enable hosting static website, you need to create a bucket and enable Static Website Hosting from properties:

![Enable-hosting](./images/aws/enable-hosting.png)

It'll ask you for the index document and error document:

![Index-Error-Docs](./images/aws/index-error-docs.png) 

You'll be given an endpoint that looks like:

`http://iqbaltesting.s3-website-us-east-1.amazonaws.com` 


More info on index and document types in the following sections.

### Endpoints

When you configure your bucket as a static website, the website is available at the AWS Region-specific website endpoint of the bucket. Website endpoints are different from the endpoints where you send REST API requests. Depending on your Region, your Amazon S3 website endpoint follows one of these two formats.

 - s3-website dash (-) Region ‐ `http://bucket-name.s3-website-Region.amazonaws.com`
 - s3-website dot (.) Region ‐ `http://bucket-name.s3-website.Region.amazonaws.com`

These URLs return the default index document that you configure for the website. For your customers to access content at the website endpoint, you must make all your content publicly readable. To do so, you can edit the S3 Block Public Access settings for the bucket. Then, use a bucket policy or an access control list (ACL) on an object to grant the necessary permissions.

### Adding a DNS CNAME

To request a specific object that is stored at the root level in the bucket, use the following URL structure:
`http://bucket-name.s3-website.Region.amazonaws.com/object-name`

If you have a registered domain, you can add a DNS CNAME entry to point to the Amazon S3 website endpoint. For example, if you registered the domain `www.example-bucket.com`, you could create a bucket `www.example-bucket.com`, and add a DNS CNAME record that points to `www.example-bucket.com.s3-website.Region.amazonaws.com`. All requests to `http://www.example-bucket.com` are routed to `www.example-bucket.com.s3-website.Region.amazonaws.com`. This means for the url `http://www.example-bucket.com`, assets will be furnished from your bucket called `www.example-bucket.com.s3-website.Region.amazonaws.com`.

### Enabling website hosting
When you configure a bucket as a static website, you must enable static website hosting, configure an index document, and set permissions. You can enable static website hosting using the Amazon S3 console, REST API, the AWS SDKs, the AWS CLI, or AWS CloudFormation. Since we're exploring S3, let's see how we can enable website hosting via S3!

0. Create appropriate bucket and add bucket policy described in the access section [below](#setting-permissions-for-website-access)

1. Sign in to the AWS Management Console and open the Amazon S3 console at https://console.aws.amazon.com/s3/.

2. In the Buckets list, choose the name of the bucket you created in step 0.

3. Choose Properties.

4. Under Static website hosting, choose Edit.

5. Choose Use this bucket to host a website.

6. Under Static website hosting, choose Enable.

7. In Index document, enter the file name of the index document, typically index.html.

8. The index document name is case sensitive and must exactly match the file name of the HTML index document that you plan to upload to your S3 bucket. When you configure a bucket for website hosting, you must specify an index document. Amazon S3 returns this index document when requests are made to the root domain or any of the subfolders. For more information, see Configuring an index document.

9. To provide your own custom error document for 4XX class errors, in Error document, enter the custom error document file name.

10. The error document name is case sensitive and must exactly match the file name of the HTML error document that you plan to upload to your S3 bucket. If you don't specify a custom error document and an error occurs, Amazon S3 returns a default HTML error document. For more information, see Configuring a custom error document.

11. (Optional) If you want to specify advanced redirection rules, in Redirection rules, enter XML to describe the rules. For example, you can conditionally route requests according to specific object key names or prefixes in the request. For more information, see Configure redirection rules to use advanced conditional redirects.

12. Choose Save changes. Amazon S3 enables static website hosting for your bucket. At the bottom of the page, under Static website hosting, you see the website endpoint for your bucket.

13. Under Static website hosting, note the Endpoint. The Endpoint is the Amazon S3 website endpoint for your bucket. After you finish configuring your bucket as a static website, you can use this endpoint to test your website.


An interesting read for serving websites using S3 via HTTPS can be found [here](https://aws.amazon.com/premiumsupport/knowledge-center/cloudfront-https-requests-s3)

#### Configuring an index document
When you enable website hosting, you must also configure and upload an index document. An index document is a webpage that Amazon S3 returns when a request is made to the root of a website or any subfolder. For example, if a user enters `http://www.example.com` in the browser, the user is not requesting any specific page. In that case, Amazon S3 serves up the index document, which is sometimes referred to as the default page.

When you enable static website hosting for your bucket, you enter the name of the index document (for example, index.html). After you enable static website hosting for your bucket, you upload an HTML file with the index document name to your bucket. Here's waht a sample `index.html` file could look like:

```html
<html xmlns="http://www.w3.org/1999/xhtml" >
<head>
    <title>My Website Home Page</title>
</head>
<body>
  <h1>Welcome to my website</h1>
  <p>Now hosted on Amazon S3!</p>
</body>
</html>
```

#### Configuring a custom error document

After you configure your bucket as a static website, when an error occurs, Amazon S3 returns an HTML error document. You can optionally configure your bucket with a custom error document so that Amazon S3 returns that document when an error occurs. You can provide a custom error document that contains a user-friendly error message and additional help. Amazon S3 returns your custom error document for only the HTTP 4XX class of error codes. After you enable static website hosting for the bucket, you upload an HTML file with this error document name to your bucket. The error document should reside in a file called `4XX.html`. So for example, if you're returning a custom error on 404 (not found error), your document should be called `404.html`. 

#### Setting permissions for website access
When you configure a bucket as a static website, if you want your website to be public, you can grant public read access. To make your bucket publicly readable, you must disable block public access settings for the bucket and write a bucket policy that grants public read access. If your bucket contains objects that are not owned by the bucket owner, you might also need to add an object access control list (ACL) that grants everyone read access. We've already discussed how to enable/disable bucket level public access. Let's look at the bucket policy for website hosting:

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "PublicReadGetObject",
            "Effect": "Allow",
            "Principal": "*",
            "Action": [
                "s3:GetObject"
            ],
            "Resource": [
                "arn:aws:s3:::Bucket-Name/*"
            ]
        }
    ]
}
```

In the preceding example bucket policy, Bucket-Name is a placeholder for the bucket name. To use this bucket policy with your own bucket, you must update this name to match your bucket name. With public access allowed and bucket policy specified, your bucket permissions should look like so:

![Final-Permissions](./images/aws/final-bucket-permissions.png)

You can now visit the endpoint and see your page! S3 is highly available and reliable and is also scalable, meaning as traffic increases to your website, S3 will automatically!