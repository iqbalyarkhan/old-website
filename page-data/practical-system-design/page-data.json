{"componentChunkName":"component---src-templates-post-js","path":"/practical-system-design","result":{"data":{"markdownRemark":{"html":"<ol>\n<li><a href=\"#system-design\">System Design</a></li>\n<li><a href=\"#generating-unique-ids-in-a-distributed-env\">Generating Unique IDs in a distributed Env</a></li>\n<li><a href=\"#back-of-the-envelope-estimation\">Back of the envelope Estimation</a></li>\n<li><a href=\"#storing-images\">Storing Images</a></li>\n<li><a href=\"#allowing-users-to-chat\">Allowing users to chat</a></li>\n<li><a href=\"#design-chat-messaging\">Design Chat Messaging</a></li>\n<li>\n<p><a href=\"#design-rate-limiting\">Design Rate Limiting</a></p>\n<ul>\n<li><a href=\"#sharing-data-between-servers\">Sharing data between servers</a></li>\n<li><a href=\"#tcp-vs-udp\">TCP vs UDP</a></li>\n</ul>\n</li>\n<li><a href=\"#design-distributed-message-queue\">Design Distributed Message Queue</a></li>\n<li>\n<p><a href=\"#design-distributed-cache\">Design Distributed Cache</a></p>\n<ul>\n<li><a href=\"#lru-cache\">LRU Cache</a></li>\n<li><a href=\"#replication-to-achieve-high-availability\">Replication to Achieve HA</a></li>\n</ul>\n</li>\n<li><a href=\"#useful-architectures\">Useful architectures</a></li>\n</ol>\n<h3 id=\"system-design\"><a href=\"#system-design\" aria-label=\"system design permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>System Design</h3>\n<p>Let's look at some example system designs and see the trade-offs between various approaches that can be used to design a solution.  </p>\n<h3 id=\"generating-unique-ids-in-a-distributed-env\"><a href=\"#generating-unique-ids-in-a-distributed-env\" aria-label=\"generating unique ids in a distributed env permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Generating Unique IDs in a distributed Env</h3>\n<p>Say you're given a distributed system and are asked to come up with a function to generate a globally unique ID for this system. On a single machine, this is simple, you just auto-increment an ID in your DB and you have a unique ID on each call. However, this isn't possible if you have a distributed system with multiple machines and multiple partitions.</p>\n<ul>\n<li><strong>Requirements</strong></li>\n<li>The ID should be unique across EVERY call and EVERY machine.</li>\n<li>It should consist of numerical values only</li>\n<li>It should fit into 64-bit</li>\n<li>Should be able to generate over 10,000 unique IDs/sec</li>\n</ul>\n<p>First thing that comes to mind is to use UUID that can be generated independently without coordination between servers. However, UUIDs are 128 bits long and are non-numeric: Example: 09c93e62-50b4-468d-bf8a-c07e1040bfb2. </p>\n<p>Another thing that can be done is to have a centralized generator. Every time you need to generate a new ID, this centralized generator is called. The issue here is that this is a single point of failure and is not scalable. It definitely won't be able to handle 10,000 unique IDs/sec. </p>\n<p>How about we just use time as the id? Hmm, ok so if I have distributed environment, it is possible that two different nodes are called at the same time to generate the id. Even if they're not, different nodes might have different clocks that might result in collisions. </p>\n<p>But the idea of using time does look promising ie using epoch time. Now to make it unique, we can add in the IP address of the server. So, we might be able to concatenate the IP address of the server with the epoch time and get a unique id right? Well, what if we invoke this function in the same microsecond on the same server? That would cause a collision!  Maybe we can use a counter that gets incremented every time this function is called. So something like: <code class=\"language-cpptext\">epochTime_serverID_counter</code>. Hmm, this would work!</p>\n<p>But wait a second, what if the machine reboots? What if it crashes, has to re-boot and then start generating unique ids again. Since the machine crashed, our counter would reset to 0. Maybe we can store this counter somewhere and have the server read it from there on restart. And every time it is incremented, we can push the counter value to this store! This sounds like a job for Redis! Yup, that would work. So, our unique ID would be: <code class=\"language-cpptext\">epochTime_serverID_counter</code></p>\n<ul>\n<li><strong>Approach</strong>\nOk, so we've deiced to have the unique ID like so: <code class=\"language-cpptext\">epochTime_serverID_counter</code>. Now, we can have up to 64 bits in the id. Epoch time takes 41 bits. How do I know that? Convert an epoch time value to binary and count the number of bits. For example,  epoch time 1288834974657 converted to binary is:</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"cpp\"><pre class=\"language-cppcpp\"><code class=\"language-cppcpp\"><span class=\"token number\">0</span>       epoch time                      <span class=\"token number\">40</span>\n<span class=\"token number\">10010110000010100100011010000001111000001</span></code></pre></div>\n<p>We're still left with 23 bits. For the sake of having a more robust id, we can add the datacenter id to the unique ID as well! So our unique ID would be:</p>\n<p><code class=\"language-cpptext\">epochTime_dataCenterID_serverID_counter</code></p>\n<p>Alright, so we've got 41 bits for epoch time. Next up, we can use 5 bits for our dataCenterID. This would result in a total of 32 data centers because <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mn>2</mn><mn>5</mn></msup><mo>=</mo><mn>32</mn></mrow><annotation encoding=\"application/x-tex\">2^5 = 32</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord\">2</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">5</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span><span class=\"mord\">2</span></span></span></span>. Our ID now is:</p>\n<div class=\"gatsby-highlight\" data-language=\"cpp\"><pre class=\"language-cppcpp\"><code class=\"language-cppcpp\"><span class=\"token number\">0</span>       epoch time                     <span class=\"token number\">40</span>   <span class=\"token number\">44</span> \n<span class=\"token number\">1001011000001010010001101000000111100000100001</span>\n                                        dcID</code></pre></div>\n<p>Next, we add serverId which we can have a bit longer, say 6 bits meaning we can have 64 servers in a datacenter:</p>\n<div class=\"gatsby-highlight\" data-language=\"cpp\"><pre class=\"language-cppcpp\"><code class=\"language-cppcpp\"><span class=\"token number\">0</span>       epoch time                     <span class=\"token number\">40</span>   <span class=\"token number\">44</span>    <span class=\"token number\">45</span> \n<span class=\"token number\">1001011000001010010001101000000111100000100001000001</span>\n                                        dcID serverID</code></pre></div>\n<p>and finally the remaining bits can be the counter value meaning <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mn>2</mn><mn>1</mn></msup><mn>9</mn></mrow><annotation encoding=\"application/x-tex\">2^19</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord\">2</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span><span class=\"mord\">9</span></span></span></span> giving us a total of 524288 per machine:</p>\n<div class=\"gatsby-highlight\" data-language=\"cpp\"><pre class=\"language-cppcpp\"><code class=\"language-cppcpp\"><span class=\"token number\">0</span>       epoch time                     <span class=\"token number\">40</span>   <span class=\"token number\">44</span>    <span class=\"token number\">45</span>   counter       <span class=\"token number\">64</span>\n<span class=\"token number\">10010110000010100100011010000001111000001000010000010000000000000000001</span>\n                                        dcID serverID</code></pre></div>\n<h3 id=\"types-of-encoding\"><a href=\"#types-of-encoding\" aria-label=\"types of encoding permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Types of Encoding</h3>\n<p>Encodings could be base36 ([a-z ,0-9]) or base62 ([A-Z, a-z, 0-9]). If you use base 36 encoding and have a 4 character string, possible number of strings would be: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>3</mn><msup><mn>6</mn><mn>4</mn></msup></mrow><annotation encoding=\"application/x-tex\">36^4</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\">3</span><span class=\"mord\"><span class=\"mord\">6</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span></span></span></span></span></span></span></span>. For 62 base encoding and 7 character string: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>6</mn><msup><mn>2</mn><mn>7</mn></msup></mrow><annotation encoding=\"application/x-tex\">62^7</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\">6</span><span class=\"mord\"><span class=\"mord\">2</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">7</span></span></span></span></span></span></span></span></span></span></span>.</p>\n<h3 id=\"back-of-the-envelope-estimation\"><a href=\"#back-of-the-envelope-estimation\" aria-label=\"back of the envelope estimation permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Back of the envelope Estimation</h3>\n<p>Below is a table explaining the data volume unit </p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 54.88431876606684%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAABR0lEQVQoz2XSh47DMAwD0Pz/R7bonuneS8UToOAODWDYoUWKYtKMRqOYz+dxuVzier3mPplMYjwe5z6dTmO1WuUO22w2cbvd4ng8Bi58sVgk93A4RLNer/Py9XrF+/2Ox+MRsP1+nwW73a47q0P8fD4put1uuzvY+XyORof7/d4tBI6Gw2E6QrTU9Xq9dPh8PpPsniAzuOmQXWPWyKfTKQXbtk13cM4KI1Ajw4gUV30jPx2Nazkvl8t0ZHyj2JErb45gzhqowc2RZ7PZj0OFljOs3KiVbznUmKCaziEnXior5/q6mshGZ9HIlQh31diHqfy7DEsMSETwnCCVYGFcFMZ11fwT1FF2FmEkTriVTWEcEYa5c2YAT67EG0H/HVkBol+i3+9nEUwEg8EgykD9Nj8jC9XjS3l0UlxBwzmod009RGuC4nr/Ap1CS9xeuDqYAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Power of Two\"\n        title=\"Power of Two\"\n        src=\"/static/fc08d92bfc92d5aecf388f5ebaef136b/1dda8/power-of-two.png\"\n        srcset=\"/static/fc08d92bfc92d5aecf388f5ebaef136b/27f03/power-of-two.png 173w,\n/static/fc08d92bfc92d5aecf388f5ebaef136b/376d0/power-of-two.png 345w,\n/static/fc08d92bfc92d5aecf388f5ebaef136b/1dda8/power-of-two.png 690w,\n/static/fc08d92bfc92d5aecf388f5ebaef136b/4fa3d/power-of-two.png 778w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span> <a href=\"https://www.amazon.com/System-Design-Interview-insiders-Second/dp/B08CMF2CQF\">Image Credit</a></p>\n<p>Some common facts: </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-cpptext\"><code class=\"language-cpptext\">               • Memory is fast but the disk is slow.\n               • Avoid disk seeks if possible.\n               • Simple compression algorithms are fast.\n               • Compress data before sending it over the internet if possible.\n               • Data centers are usually in different regionsundefined and it takes time to send data between them.\n               </code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 550px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 29.272727272727273%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAGABQDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAGwAD//xAAUEAEAAAAAAAAAAAAAAAAAAAAQ/9oACAEBAAEFAn//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAQ/9oACAEBAAY/An//xAAWEAEBAQAAAAAAAAAAAAAAAAAAIRH/2gAIAQEAAT8hiNf/2gAMAwEAAgADAAAAEAAP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAGhAAAgIDAAAAAAAAAAAAAAAAAAERQSFhof/aAAgBAQABPxCbK8myGirh/9k='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Power of Ten\"\n        title=\"Power of Ten\"\n        src=\"/static/a68ec88b918976a97c85a9df1a08b912/c603d/powers_of_10.jpg\"\n        srcset=\"/static/a68ec88b918976a97c85a9df1a08b912/6bc31/powers_of_10.jpg 173w,\n/static/a68ec88b918976a97c85a9df1a08b912/89707/powers_of_10.jpg 345w,\n/static/a68ec88b918976a97c85a9df1a08b912/c603d/powers_of_10.jpg 550w\"\n        sizes=\"(max-width: 550px) 100vw, 550px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span> <a href=\"https://www.amazon.com/System-Design-Interview-insiders-Second/dp/B08CMF2CQF\">Image Credit</a></p>\n<ul>\n<li>Single Character requires 1 byte</li>\n<li>Integer requires 4 bytes </li>\n<li>Media requires 1 MB </li>\n</ul>\n<p>For variable length strings, we need this calculation to determine the number of bytes needed:</p>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mtext>Total size (in Bytes)</mtext><mo>=</mo><mo stretchy=\"false\">(</mo><mo stretchy=\"false\">(</mo><mtext>Number of bits used to encode a single character</mtext><mo stretchy=\"false\">)</mo><mo>∗</mo><mo stretchy=\"false\">(</mo><mtext>Number of characters</mtext><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">/</mi><mn>8</mn></mrow><annotation encoding=\"application/x-tex\">\\textrm{Total size (in Bytes)} = ((\\textrm{Number of bits used to encode a single character}) * (\\textrm{Number of characters}))/8</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord textrm\">Total size (in Bytes)</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mopen\">(</span><span class=\"mord text\"><span class=\"mord textrm\">Number of bits used to encode a single character</span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord text\"><span class=\"mord textrm\">Number of characters</span></span><span class=\"mclose\">)</span><span class=\"mclose\">)</span><span class=\"mord\">/</span><span class=\"mord\">8</span></span></span></span></span>\n<p>If we are using ASCII encoding, we need 8 bits to encode each character, so Number of bits used to encode a single character = 8\nIf we are using UNICODE encoding, we need 16 bits to encode each character, so Number of bits used to encode a single character = 16.</p>\n<h3 id=\"storing-images\"><a href=\"#storing-images\" aria-label=\"storing images permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Storing Images</h3>\n<p>Say, for example, that you're creating an image sharing system (instagram like service) and need to store images for your service. How/where would you store them? You have 2 options: use a DB and store images as blob (binary large object) or use a distributed file system and have a DB store location of images for each user. Let's have a look at the pros and cons for each:</p>\n<p><strong>Why DB</strong></p>\n<ul>\n<li>DB is ACID (Atomicity, Consistency, Isolation, Durability) compliant</li>\n<li>DB provides data integrity between the file and its metadata (Files can be deleted from FS causing database integrity to be compromised.)</li>\n<li>Much easier to perform backups as the entire process is built-in</li>\n<li>Database indexes perform better than file system trees when more number of items are to be stored</li>\n<li>File deletion and updates becomes simpler as opposed to a File System.( In the case of FS, we first delete the mapping from DB and then delete the image from FS as well. There’s this extra overhead to make sure that the file in FS is deleted. In DB this operation is atomic)</li>\n</ul>\n<p><strong>Why DFS</strong></p>\n<ul>\n<li>If your application uploads a large number of high-quality images, your DB backups become huge, which can have a significant impact on the makes replication speed</li>\n<li>FS can be accessed via a CDN without allowing the user’s request to go through your Application and Database layers</li>\n<li>Needless to say, this will be cost-effective as compared to DB</li>\n<li>Easier in cases where files has to be shared with third-party providers</li>\n<li>Storing/retrieving BLOB in DB is a heavy process</li>\n<li>For the application in which the images will be used requires streaming performance, such as real-time video playback</li>\n</ul>\n<p>The case against DB is that for images, we aren't ever going to use ACID properties (those are for financial transactions etc). DFS is cheaper as compared to a DB, it is faster and a DFS can make use of a CDN to render our images for us. </p>\n<h3 id=\"allowing-users-to-chat\"><a href=\"#allowing-users-to-chat\" aria-label=\"allowing users to chat permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Allowing users to Chat</h3>\n<p>XMPP, an Extensible Messaging and Presence Protocol, helps to build a real time chat application. XMPP provides an open and decentralized instant messaging services. As the name indicates, it is a highly extendable protocol formerly known as Jabber protocol. To exchange the information, XMPP uses Extensible Markup language (XML) as the base format. XMPP uses the TCP protocol to maintain connections between 2 clients.</p>\n<p>A simple XMPP architecture consists of a server and two clients. Every client acts as the part of a common domain where the servers can also communicate for the purpose of routing between domains.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 21.828103683492497%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAAAsSAAALEgHS3X78AAABHElEQVQY0z2OvS8DcQCG7/+RGOzCYGDqYjR169SFpaE0iEGEsmAqA5KLNNEw2NQgEQYf1Wuid9dWEySuX7nf/e7z0Tbh2d43eZ+8ShRFNJtN3soahmlSq9eAiD9a7TbVqk690SAMg//eEYKyVkHXDXTDGOYBys2HT7zQIZn/IXlmEd9vod55Q6lqBaRNwbLWZqnUYeFFUukGuH5EqihIDDaqRSJnkTqx6dgRytGzx8ieIHboML0lGE3arBw7fWHAoukSK0nmXl1mHyVj1w7FT4+u8BnPCaYOHGaygsmMzcS84MsKUR76D9NXkvULyca5JJ1zuL73hvcvv302qy477y7bmsvak8TohfhBxO6tJFPo7/KS1VOHrCrpiYhfp1cQ9pmr6UAAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"XMPP\"\n        title=\"XMPP\"\n        src=\"/static/d527af46a6735b6995513f73acaafa7a/1dda8/xmpp.png\"\n        srcset=\"/static/d527af46a6735b6995513f73acaafa7a/27f03/xmpp.png 173w,\n/static/d527af46a6735b6995513f73acaafa7a/376d0/xmpp.png 345w,\n/static/d527af46a6735b6995513f73acaafa7a/1dda8/xmpp.png 690w,\n/static/d527af46a6735b6995513f73acaafa7a/e558e/xmpp.png 733w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span> <a href=\"https://blog.mirrorfly.com/xmpp-use-cases-for-scalable-chat-platform/\">Image Credit</a></p>\n<p>XMPP protocol is a great fit for Real-Time Web applications like Live News, Interactive web page, web games and web chat. It provides inbuilt security with multiple layers. Moreover, here the users need to authenticate both host servers as well as messages to prevent the risk of spoofing. Eventually, it eradicates the fear of spamming. Now, when you use XMPP in a chat service, you need to able to keep track of the user ids and connection ids that are being used by each user. To do so, you can have a <strong>connection service</strong> that maintains this information for you:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 664px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/e23888c3ea53e52a0b07e60826e00e85/32c46/chat.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 51.50602409638555%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsSAAALEgHS3X78AAABBUlEQVQoz42S2wqDQAxE+///55MPoogi3u93U05KZFta6MIQdzeZmcR9HMch53kK0WB74nVdN2zv3n/Gx7cLsO+79H0vXde9oW1bGcfxqwGghNu2KQGRPWueZ4XrkGVCRmC1t8N1XSXPcwmCQNI0laqqlKiua3XEGoZBz6ZpUmIIqUuSRBHHsWRZ9iKEnRZIonBZFlUMw1B839cWEWmaRkUo4qwsSyUhDxRF8WqZBFvuwEnAsY3AzcEA7hGKokhd2hjUobWDOwhxShue5+k43J+DO/bMjjwT4U4JOaQIN0QKIEfI4P5RF9SaEDU6Q9wxH8AFyu4z+Hyjv56Lfd/v0MUvgn/wBCdhCsChC885AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Chat\"\n        title=\"Chat\"\n        src=\"/static/e23888c3ea53e52a0b07e60826e00e85/32c46/chat.png\"\n        srcset=\"/static/e23888c3ea53e52a0b07e60826e00e85/27f03/chat.png 173w,\n/static/e23888c3ea53e52a0b07e60826e00e85/376d0/chat.png 345w,\n/static/e23888c3ea53e52a0b07e60826e00e85/32c46/chat.png 664w\"\n        sizes=\"(max-width: 664px) 100vw, 664px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>XMPP uses XML to exchange data between client and server. Whenever a client connects to an XMPP server using a chat application, they transmit information with each other which is also known as an XML “Stanza”. Stanza is a basic unit of communication in XMPP. In XMPP based communication, there are 3 types of stanzas:</p>\n<ul>\n<li>Message: Used to exchange messages.</li>\n<li>Presence: Used to exchange online and subscription status.</li>\n<li>IQ (Info/Query): Used to control dynamic settings of the communication that is controlled over the server.</li>\n</ul>\n<p>Advantages of XMPP:</p>\n<ul>\n<li><strong>Extensible</strong>: XMPP can be used to send different message types including text, pictures, videos, and audios</li>\n<li><strong>Decentralized architecture</strong>: Which means anyone can set up an XMPP server</li>\n<li><strong>Security</strong>: XMPP allows developers to set up a separate storage server which can have its own encryption and security standards</li>\n<li><strong>Flexibility</strong>: Can connect to non-Jabber programs as well using special gateway services</li>\n</ul>\n<p>Disadvantages of XMPP:</p>\n<ul>\n<li><strong>No default way to assure message delivery</strong>: XMPP doesn’t provide the ability to request message delivered confirmation by default. The developers need to set up message receipts manually.</li>\n<li><strong>Slow speed</strong>: The decentralized architecture of XMPP allows anyone to run his/her own server, however, it does eat up on the speed of the connection.</li>\n</ul>\n<p>We've already talked about websockets and WS can also be used to implement chat based applications. Let's see its advantages and disadvantages:</p>\n<ul>\n<li><strong>Speed</strong>: With a centralized and persistent communication connection, WebSockets are the fastest online communication method.</li>\n<li><strong>Unlimited open sessions</strong>: There can be an unlimited number of user sessions on a single app.</li>\n</ul>\n<p>Disadvantages:</p>\n<ul>\n<li><strong>Low Security</strong>: Although WebSockets utilize WSS(Websockets of SSL), the technology is still new and prone to attacks like XSS and DDOS.</li>\n</ul>\n<h3 id=\"design-chat-messaging\"><a href=\"#design-chat-messaging\" aria-label=\"design chat messaging permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Design Chat Messaging</h3>\n<p>Requirements:</p>\n<ul>\n<li>Users should be able to chat in a group</li>\n<li>Sent + Delivered + Read Receipts</li>\n<li>Person online/last seen</li>\n<li>Chat history (permanent vs temporary)</li>\n</ul>\n<p>Ok, let's start with the basic setup of how we want our users to interact. We'll use an API gateway which'll capture requests from client:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 373px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/1818904cadfe32d89e5945a6b8d92e94/2878e/messaging1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 112.6005361930295%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAXCAYAAAALHW+jAAAACXBIWXMAAAsSAAALEgHS3X78AAABzUlEQVQ4y52ViY7CMAxE+f+P5Co3RZzlBqPn1QSTDazYSFbS1B4fY7ety+Vit9vNrterxXMu8R37/X73PQrvWlJkRyJACfB4PFrTNLbf7110ln4ClOBZ3nNA7ofDoc3nc1ssFlbXtS2XS6uqylarlbFaMsDL4XDwCDiz5+AsQPJFlOv1+gcQA7xNp1ObTCYeAWd2HJxOJxccIOjEGrI2m80TkEtSIILBYOBChNwRDYqkw97v963b7bqhoo+APHuEGIzH45fa8KwIYjToxHsBIh5hZPl8Pqf9XdvMZrMiYIpQALvdLhGjVohgOeDHlEmRVEiTGlJ4zoDJUCyjJyCt7Xb7TFmkEAHM0lN44w7hTK+x867X6zk4dwCpZQD0CAEUKUQaSYk1RWgbUqY8nU7HHcA89glQtcGAfpOxRinOOQvAUsovpEghKqpucQS5i6TExk41RJFU8CCWSQmv/2obXjJqENBut11Go5ETRAnyT9ufgGob6oYyZ4xxUho9yCiN3kvKpAirMIwArFZ619gfJ0UEaORKX27plWb5F8vROH7O82cMKEXOMmDp8/XNPwUQxhIhUpWGcSXKFGGs06d/SuzLUhbofJVyfh8d6vkBXhUAEpcjISoAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Messaging\"\n        title=\"Messaging\"\n        src=\"/static/1818904cadfe32d89e5945a6b8d92e94/2878e/messaging1.png\"\n        srcset=\"/static/1818904cadfe32d89e5945a6b8d92e94/27f03/messaging1.png 173w,\n/static/1818904cadfe32d89e5945a6b8d92e94/376d0/messaging1.png 345w,\n/static/1818904cadfe32d89e5945a6b8d92e94/2878e/messaging1.png 373w\"\n        sizes=\"(max-width: 373px) 100vw, 373px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>Ok, to allow your users to chat, you'd have to keep track of connection information (port etc). This information can be stored in API GW. However, the downside is that our system would not be loosely coupled. We want a separate microservice that handles all sessions for us, leaving the gateway to concentrate on the edge functions. So, the flow would now be that the user connects to our API gateway, and API gateway calls the <strong>sessions</strong> service. </p>\n<p>Our sessions service would reside behind a load balancer and we'll have multiple servers working as sessions service. The service would also need access to a DB where it'll be able to update/retrieve user session information. For that, we'll create a table with userID, connectionInfo etc. The type of data store I'm thinking here is a MySQL DB since we'll be able to quickly access user info by creating an index n userId. So, our architecture will look like so:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/8de4c6545a0eb27072193e18161cf29a/b0803/messaging2.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 53.527435610302355%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAABRUlEQVQoz51Ta0/DMBDb//+VAxVoy9rlncurJnfVxsY+AKtkKU4Tn3NxDrVW1FoQk0fMrsODSsDZLHj7eMX7NOBznRCSgycr4PEjLHJJOGwbUGrexSjCOiOIFISHGECJZE3bGjY01FaE57KjlLIbyQEHrXeBQA7GWLTWQEQIIXREaK0RY0TOGeM44Xh8gbUO67JinmbwCVttSIV2wWVZYKyGC0Y288ebnXPC+T+PucA4jhiGAd77XtxgnmcxcCeolILzVhw656+C7HLr/RAHvKmDOePCGfsd3AieTgu0UeJQKS2VuQgL7ot/x53DkgtSJrnZ2HvGDlJK0rdvB/8Q5L6c1QrjFdRZXY/8tGCi1GMRhfibHj4t2NomgeRw8pGdsz0WVrLHgS8/UR7nWJRylCwemPCkJyPh5sRf0u9l/BfwK9Li8gvqqFoxe3hKvAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Messaging2\"\n        title=\"Messaging2\"\n        src=\"/static/8de4c6545a0eb27072193e18161cf29a/1dda8/messaging2.png\"\n        srcset=\"/static/8de4c6545a0eb27072193e18161cf29a/27f03/messaging2.png 173w,\n/static/8de4c6545a0eb27072193e18161cf29a/376d0/messaging2.png 345w,\n/static/8de4c6545a0eb27072193e18161cf29a/1dda8/messaging2.png 690w,\n/static/8de4c6545a0eb27072193e18161cf29a/b0803/messaging2.png 893w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>Now, when userA wants to connect to userB, userA will send a <strong>sendMessage(B)</strong> request to our API GW. API GW will forward that request to sessions service. Sessions service will determine which port userB is connected to (using information from the DB) and will forward request to the appropriate connection and thus sending the message to userB. Now, to actually send message to userB (client) from server, we can use multiple techniques as discussed earlier such as long polling, ajax, websockets or xmpp etc. Now in the <a href=\"#allowing-users-to-chat\">chat</a> section, we compared XMPP and websockets. One advantage of using websocket is that it allows for unlimited open sessions over TCP. Since we're looking for group chat as well, we'll go ahead and use websockets that communicate via TCP. </p>\n<p>One requirement for our chat app is that the sender should be able to see sent + delivered + read receipts. In order for us to be able to show to userA that the message was <strong>sent</strong>, we can send a response back from session service to gateway and back to userA that the message will be sent when possible. In order to store this information, we'll need another DB for our sessions service. This new DB will hold our message statuses. This flow is shown with red arrows in the diagram below:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/7abdc1a0abd425dbde2bbff0907f52c3/683fc/messaging4.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 51.25408942202835%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsSAAALEgHS3X78AAABf0lEQVQoz2VS2XLCQAzL//9jO1NIC4EkZLP3FVVeSgbog2Y9tleWj66UAkEtFT46uKjhk0XIDoue8X0+4jT0GG8Xxg3jr/DR/tm62Z2Q5ZxQa4VLkuCh9dogdmIsxIBUEnLJRGr5uWbEHBFTbDmJto0rOmMMhssFy3WEpSJ7uyHG2OANq2uDaZ7h1Iq0rjh8HdAfe9hpxsQ/w3BBCOEuiEo77z1WJjrrWkvBuzaCIgmLgmds1RqReSVnXIcB4+nMPI/recDP6YTE4vKnEVprMY5XKCownrAG4hOExFFs215AsInNWCbJmWR935M8MFbaHDuRK20752Ccoq05vzuitPK3tB1UmakusaPvwwEfn5/Mi68tT9NERY6bparg98+P2ZR3UvrqVrms2IQ8/HvLM4eulIIyNyxq4RZzw52w/Cfkttup1bIXlAtohOLYOKdat/v9BanqG6SVrW7t0wvK0/tkN8IHuzjkjmzQnCXvkHA8VDlWKeTf7ee32QYmKPwCCYcJulJ9FYIAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Messaging4\"\n        title=\"Messaging4\"\n        src=\"/static/7abdc1a0abd425dbde2bbff0907f52c3/1dda8/messaging4.png\"\n        srcset=\"/static/7abdc1a0abd425dbde2bbff0907f52c3/27f03/messaging4.png 173w,\n/static/7abdc1a0abd425dbde2bbff0907f52c3/376d0/messaging4.png 345w,\n/static/7abdc1a0abd425dbde2bbff0907f52c3/1dda8/messaging4.png 690w,\n/static/7abdc1a0abd425dbde2bbff0907f52c3/683fc/messaging4.png 917w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>When userB opens the app on his/her end, the message gets sent to userB's phone. Upon receipt of the message, userB's phone should respond with a message saying that he/she received the message from userA. At that point, the <strong>delivered</strong> confirmation flows from userB to API GW to sessions service and back to userA. This done via a TCP acknowledgement. userB will send back the info that it received message from userA and sessions service will deliver the delivered receipt by looking up the box where userA's connection resides and will send the confirmation back to userA. This flow is shown via blue arrows in the diagram below:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/0ab8c22cfb30c170c9bfa2e57ef766fb/043fa/messaging5.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 51.7051705170517%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsSAAALEgHS3X78AAABkUlEQVQoz21S2XLCMAzk/3+RtwIpIYnj+3a269AwdKhnduRDXmklnWqtOBCSg08WITvE4iH1gtv3F77HK2Yxvt7fEd72LhqcOlEpBa1tJOJDdLDOwhiNmAJKzUgp7ra2uttSiFaQaVNOtIn3BSauOBljMI4j1mmGkgvEYyJ5I0mC1STWBvOyQK8KVkgMtxuu1yvcIiDmGePjAe89tg2wUeEUQoDWGlJZSKewrBJ99czXWUAuEkIqaOOgbMDXZcB8vyPx38xEbsOAGAM2KtwJrbWYpokSLS8MFG3OGc5ReqBUOqZcKKkilQrrIzaSVfo8SHhhtnuGB2HgJ0vZzgdIryGUwZG1Mp5FL0Rm0Z9IJCp8L/QfLhecz+dPyUKInSSyu44NOSSnyGy2xprWNzQ2p+02ss5dydHUl+SZxVVKsUYCCxvQV3fqQXpn30fribLbPQAD9nOr7UnYIz2zaPtM9YiZNQuUFHuGjNydX2jt77l2QnI0cA717xz+RugXPrI53nAWNQN4liH8A/9xTjnChBU/2XsIslhOfCwAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Messaging5\"\n        title=\"Messaging5\"\n        src=\"/static/0ab8c22cfb30c170c9bfa2e57ef766fb/1dda8/messaging5.png\"\n        srcset=\"/static/0ab8c22cfb30c170c9bfa2e57ef766fb/27f03/messaging5.png 173w,\n/static/0ab8c22cfb30c170c9bfa2e57ef766fb/376d0/messaging5.png 345w,\n/static/0ab8c22cfb30c170c9bfa2e57ef766fb/1dda8/messaging5.png 690w,\n/static/0ab8c22cfb30c170c9bfa2e57ef766fb/043fa/messaging5.png 909w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>The flow above is also relevant for read receipt. UserB would send another message back to our API GW once the app is opened and message is read on userB's phone. This will result in a <strong>read</strong> receipt being sent back to userA. </p>\n<p><strong>Let's tackle our third requirement: last seen/online</strong></p>\n<p>Let's say userB is online and is chatting with others. UserB will send requests to our API GW via websocket connection. Remember, we've already stored userB's connection information in our sessionsDB. We can look at the sessionsDB to see whether connectionInfo related to userB is actually showing an active connection or that the connection has been closed. If it is active, we can show to userA and userC that userB is online. If connection is inactive, we need another method to determine last-seen. For last-seen, as userB exits the app, we can send a message from userB's phone to API GW and to session service saying that userB has terminated the connection. We can store this information in a Redis cache data store with userB's uniqueID and time-stamp. So, any time userA or userC clicks on userB's profile, we can display the last time userB was online: which would be the time-stamp when userB exited the app. </p>\n<p><strong>Group messaging</strong></p>\n<p>Let's focus now on group messaging. Earlier we talked about two users chatting; what if we have multiple users who're part of different groups. In the diagram below, users are grouped as shown and each user can be connected to a different API GW (remember, API gateway is also a service which needs to be highly available and resilient):</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/8da53acf9ea9b7a3a55b0a0916df31ba/22cd6/messaging6.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 42.2668240850059%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAABJElEQVQoz42SyY6DMBBE/f+fGIVESECGsNvgjaXismLEYTSaQ8mo1X6urkYc+w5q/8p7D2MMtNbYtu3fSveFMhrjrLBYA2ctxnFE13WYpgl1Xcemv0DHccRzWRZIKSEaOaDqanRqgg5F510Evt9vNE2DdV1PB/xOD/AkjCD25nmO5/MJ4W0POf7AmTGMaTHPc3TJxmEYToAN7glgrSxLVFUVp6ArRtS2bQSL1etQkFi9wRJyI8w5F4FKqQgoigJ938cLjOF+v8caQcycvY/HA7fbDaIPjupwqVcSy9cdX6UIeL1eMQIuKbnkyUkISpMQmGUZxKRVgA1QZsa+7edIKUO6JSRt8brRq9KfIbwZMIUMVydDIWza2TgqHSRYWsxvui6N+gAXxGqhYIYnnAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Messaging6\"\n        title=\"Messaging6\"\n        src=\"/static/8da53acf9ea9b7a3a55b0a0916df31ba/1dda8/messaging6.png\"\n        srcset=\"/static/8da53acf9ea9b7a3a55b0a0916df31ba/27f03/messaging6.png 173w,\n/static/8da53acf9ea9b7a3a55b0a0916df31ba/376d0/messaging6.png 345w,\n/static/8da53acf9ea9b7a3a55b0a0916df31ba/1dda8/messaging6.png 690w,\n/static/8da53acf9ea9b7a3a55b0a0916df31ba/22cd6/messaging6.png 847w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>Now, here's the requirement: we want to determine if the user we just received a message from is present in a group and if the user is sending a message to a group or a single individual. If it is a single individual, the API GW call would be <strong>sendMessage(B)</strong> as we discussed earlier. If it is a group message, message received on the API GW would be <strong>sendGroupMessage(userA)</strong>, meaning userA is trying to send a group message to his/her group. Now, we need to determine what group userA is trying to send message to. If we ask session service to determine that for us, we'd be coupling our functionality so instead, let's have a separate service that handles our group information. Let' call this group service. What will now happen is that if sessionService receives a group message request, it'll call groupService to determine all the users in that group. GroupService will return that information, which'll be connectionID (remember webSockets allow us to have multiple chat sessions), where we'll be able to send message to the entire group. Group service needs to have a data-store where it converts groupId to connectionIds since different users can be on different connections:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/96af3d5ac10f12b1d4b8d7675e4e5100/2629a/messaging7.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 43.93939393939394%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsSAAALEgHS3X78AAABRElEQVQoz31Si46CMBDk/79QJWhOEHkUaSkgrzrXWa9GL5cjmRT2MTuzJVq2Fdu2Cfq+h1IK1lpBiP8H55yc6/rkia6NgrIGxhiM4witNZqmQVmWmOf51RDweDwEIX6/31EUBfI8l/ropivYoZXENE2oqgp1XcN0HZZlBn6aSUKCYRgErOdwCknTFOfz2dcviEarsM2dt2slSVKC9tlk+wG6bWUFl8sF+/0eh8NBXNARn9bnKUII53XB5F9IxokMjqKiR5LmiE9frzVwEK3RYlBKsjiOsdvtJB9ldYnKaJlGVbScX6/I68bjhtXb5sLD7rhb1nANjPPkd5Zlz0u5tYVn7sQeVdIWT9UaX+A+LoWKjscjkiQRlYH03V00jRrb0ovccP1U6t5+iQDm2BRquFcShSFC6Hh77lPJb6L3+F8IOybhN+CNtr+KtKWSAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Messaging7\"\n        title=\"Messaging7\"\n        src=\"/static/96af3d5ac10f12b1d4b8d7675e4e5100/1dda8/messaging7.png\"\n        srcset=\"/static/96af3d5ac10f12b1d4b8d7675e4e5100/27f03/messaging7.png 173w,\n/static/96af3d5ac10f12b1d4b8d7675e4e5100/376d0/messaging7.png 345w,\n/static/96af3d5ac10f12b1d4b8d7675e4e5100/1dda8/messaging7.png 690w,\n/static/96af3d5ac10f12b1d4b8d7675e4e5100/2629a/messaging7.png 858w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>There're multiple improvements to consider: </p>\n<ul>\n<li>We can have consistent hashing for db partitioning </li>\n<li>We can have MQs between services to handle failures</li>\n<li>We can have retry mechanisms between services </li>\n</ul>\n<h3 id=\"design-rate-limiting\"><a href=\"#design-rate-limiting\" aria-label=\"design rate limiting permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Design Rate Limiting</h3>\n<p>The requirement here is simple: we already know what rate limiting is. Now, we need to design it for our service. Before we begin to design rate limiting for a distributed system, let's design one for a single server first! </p>\n<p>On a single machine, all we need to worry about is the fact that there's a rules DB that'll hold the criteria based on which we'll throttle requests. We'll have a background process that routinely polls the DB for these rules and saves them in memory. Disk reads are expensive so we'll look to save these rules in memory using Redis cache. We'll check these cached rules whenever a request comes in and determine whether the request can be allowed through or not. Next, we'll have to keep track of the number of requests made by the client (we can id the client based on their IP address for example) in the past second and check whether the threshold has been reached as set in cache. If threshold is not reached, we can allow our request to go through. If threshold is met or exceeded, we have 3 options: drop the request, send back a 503 (service unavailable) or 429 (too many requests), or add the request to a queue and wait for threshold to recede:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/595a2ca3a5a61950f220baf78b08f02c/28daa/ratelimiting1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 39.70080552359034%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAABDElEQVQoz5VR2XKDMAz0h/RKQgCDDeY+EjKd/P8/bbUa3GE6fWgfFixZXq1W5uNa4CfOmYNvR/hmxCX3eLvkeE+sgucYa/2eP6WlxoafWBzPV1uh7heUoUdRd0gkJnLXSKMJrhm0ERuTyPoW0+0Ty/aEYTI+4KUSFrWCdyR2YRDyAc24CtmouWF9oF82dPMd6+MJW3VopxtMUfeoulnVZC7g5ZwpOc/8k/hVckQmCitRGIYFfBctSsuAXFTSJkOiqLCfNx2HnVjAsUgc7WANlfCO6r993H3nhIa+sBu9yqQTL6mESKzX3NFfXYjgt2XqUuJCjuBS0t3D9ED4F5hjcNpVcLQgxtN8Kv0P4RcXAu0NEfbyKwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"RateLimiting1\"\n        title=\"RateLimiting1\"\n        src=\"/static/595a2ca3a5a61950f220baf78b08f02c/1dda8/ratelimiting1.png\"\n        srcset=\"/static/595a2ca3a5a61950f220baf78b08f02c/27f03/ratelimiting1.png 173w,\n/static/595a2ca3a5a61950f220baf78b08f02c/376d0/ratelimiting1.png 345w,\n/static/595a2ca3a5a61950f220baf78b08f02c/1dda8/ratelimiting1.png 690w,\n/static/595a2ca3a5a61950f220baf78b08f02c/28daa/ratelimiting1.png 869w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>Cool, we've got the design working for a single server. Now, let's talk about a simple algorithm to handle rate limiting: bucket algorithm. Here, the idea is simple, we will have a bucket with <strong>tokens</strong> and each request from the client will deplete the tokens present in the bucket. Each second that passes, we'll refill the bucket with one token. Now, say for example we start with one server that has one bucket with 4 tokens (ie 4 requests per second) and receives 5 requests within the first second, first 4 requests will be allowed to go through while the final request will be throttled. That's the algorithm in a nutshell for a single server. </p>\n<p>Now imagine, these requests coming in to our distributed microservice. Say we have 3 hosts handling our requests, where each host is initially allotted 4 tokens. Since our architecture would have load balancers, say our requests are distributed like so:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/8178beeb748f5bee94543f57738e7e0e/4c275/ratelimiting2.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 59.58605664488018%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsSAAALEgHS3X78AAABwUlEQVQoz31T70/iQBDdP/y+3F/iJX4xfjCCiZfcaTDoxVMQjBSQlgKRCv0BsYV2qWW7z92VYoHjJnnpzLyZN7PbLIEwzrmCtOl0ivF4DM/zYNs2LMtSOcdxFFzXVbyEjOU365VfgpxlxLYFQaCE/2dZL9neMPMl0jRVOV3XoWkaKKUqlvl83d4NvwQ3h3S7JgqFAqKI7gzdL7hnS2mWNUT5qoQ4XvyTz18VyRPbpOJSJj0FzsVRV8dd7bBTTzaPyjeE+OoOpVDKll/Ca47v9JL3JAVjaSaLxftyozhO2OeWQnS5ZEgYX9eqOGG5XgbSt0MEsfhz1Fdp4zVEIgrlRDlIF3E2bjJnGE3oelPPX2AUCD+eqZqOFYK0X3w4eg1+8RuoUUZz8AbfnyEKQ8zmEZ6eh6DDJ8SjJkaDHszXADQKBeYYunP0Wg3Mzr8jbPyENvBB6rqN6+IRKudHuC8eolwbfL4C8Uoc10Pp5hF/Tw9QOTvE1e8LNEwHnmvDdcbovExwcXKMqui9K/xAqdoD0Y0u6q0+Lv/UcFNtoflsoGeaMFdodUzc1jv4Va7goWHAEPUZJ/16u4/S7SOuRa/WNvABOXuUiY1fxOMAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"RateLimiting2\"\n        title=\"RateLimiting2\"\n        src=\"/static/8178beeb748f5bee94543f57738e7e0e/1dda8/ratelimiting2.png\"\n        srcset=\"/static/8178beeb748f5bee94543f57738e7e0e/27f03/ratelimiting2.png 173w,\n/static/8178beeb748f5bee94543f57738e7e0e/376d0/ratelimiting2.png 345w,\n/static/8178beeb748f5bee94543f57738e7e0e/1dda8/ratelimiting2.png 690w,\n/static/8178beeb748f5bee94543f57738e7e0e/4c275/ratelimiting2.png 918w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>We've already consumed our allotted 4 requests for the current 1 second window and should throttle all remaining requests HOWEVER, each of our hosts still has tokens available. How do we make sure we throttle our requests? We need the hosts to talk to each other and determine the TOTAL number of tokens consumed:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/33d32425ebb80eb7e857ee9c0e3ce1be/355fb/ratelimiting3.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 57.01598579040852%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAABr0lEQVQoz3VSTU/CQBDtz/fo0Z/gwYPx4MEQSBASQBEoLUKN2BYbU6AflI+ybbfP2cVqITjJS3bfvDc7s7tKnucog3OOIAgQhiF835eIokjuBS/geZ5EHMcQUfYrOAlBJknyiyzL4DgOXNeVh5VzYl94ilBOOzwXhmHAtu2zuVP/mYLH44vodrvodNpnC5Q52eF/J5ZHCQMPge8dcQedXBx5lXi7JvFSmli8LSU5ctFh+RpEEeJErtDwlCEKA2zXEfIshZKlCXa7Hb3kRoo4+fcslaOL2Cdcjs55Jtc//SEmTXHUirwJY0RzukMSb3YMjpcASwMRdTtb7imZIU1T2C6JM46UMJtvwBIqxIlfMGxdE4gc2EuGeH/4EYoY9WsRotcdYHZ3gXHlGtp0QWP4CMIVeoMx3us3MFv3UCef9P/Ev1xhMPrA5PYSs4cr9McO5gu658CHYpkmTNPCy+AV1ccn1AjaeArbsmAR+pqBaq2BSvUR/eEElkk5gqobqDWeUat3SPMmtSbVUlRVhcBI1zAcqtC0IXRCwevEawIip/bQbDbRabcw0g5a4dH1P/03m39EzxMAsFsAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"RateLimiting3\"\n        title=\"RateLimiting3\"\n        src=\"/static/33d32425ebb80eb7e857ee9c0e3ce1be/1dda8/ratelimiting3.png\"\n        srcset=\"/static/33d32425ebb80eb7e857ee9c0e3ce1be/27f03/ratelimiting3.png 173w,\n/static/33d32425ebb80eb7e857ee9c0e3ce1be/376d0/ratelimiting3.png 345w,\n/static/33d32425ebb80eb7e857ee9c0e3ce1be/1dda8/ratelimiting3.png 690w,\n/static/33d32425ebb80eb7e857ee9c0e3ce1be/bcbcb/ratelimiting3.png 1035w,\n/static/33d32425ebb80eb7e857ee9c0e3ce1be/355fb/ratelimiting3.png 1126w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>Host A should see that the other 2 hosts used up 3 tokens in total and reduce that number from its available tokens. Hosts B and C should do the same leaving us with this:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/c99459762c16637920cfc9ca9f6c0d3f/4a8ee/ratelimiting4.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 57.466063348416284%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAABnElEQVQoz21SDXObMAz1//9Vu7AAvV1HwZBC20FI11KWBEio8wGGN9kNlMtFdwLp6elJNjDcsK7rRu/7HnmeI8syHV/XlA1vZUwlU79lURQhDKObtet+pjS+Ac0Yc7WFMs45DGN2U+AL+3K9IYXTeRgGTI/yWe+xq4pLvZ8ID5x+rLHDJ5HLAlW5RXM6To5Cd6Q3vBrYTXGVtxA0cL+r0MkGrG1OEEJgt6t1UXY9Tmc5Ch3PwwfoKJaj8LmRaFoS7iXqWuBwoGU6SXdIj1qc8XctNHGIFS5lizirIduWRCUSipum1SLZVqDYH3XP+0agqk+6h1VlibePNX4/viFfbxElOfznjO6sRElXofDXbEOcDe4pLopCHy+MP+C/ZPi3KeCExHlf6x6WpimS5RKO/wLDfsDszsMiirFapVhRzVv8gUHYD9OBw5+QLhPCE4RPMea/AswsB/f8GXGyhNJi6pdQvgh8cM+Fzz0EKr7CXddB4Dkw5was+U8suIvA5/DcB83xL3xmWRYGt22b3jam2IArN02T8qnbl55v7n9rOj3jinlDKgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"RateLimiting4\"\n        title=\"RateLimiting4\"\n        src=\"/static/c99459762c16637920cfc9ca9f6c0d3f/1dda8/ratelimiting4.png\"\n        srcset=\"/static/c99459762c16637920cfc9ca9f6c0d3f/27f03/ratelimiting4.png 173w,\n/static/c99459762c16637920cfc9ca9f6c0d3f/376d0/ratelimiting4.png 345w,\n/static/c99459762c16637920cfc9ca9f6c0d3f/1dda8/ratelimiting4.png 690w,\n/static/c99459762c16637920cfc9ca9f6c0d3f/bcbcb/ratelimiting4.png 1035w,\n/static/c99459762c16637920cfc9ca9f6c0d3f/4a8ee/ratelimiting4.png 1105w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>How do we share information between hosts? </p>\n<h3 id=\"sharing-data-between-servers\"><a href=\"#sharing-data-between-servers\" aria-label=\"sharing data between servers permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Sharing data between servers</h3>\n<p>We need to be able to share data/information between servers. Let's look at the different ways we can do this:</p>\n<h3 id=\"message-broadcasting\"><a href=\"#message-broadcasting\" aria-label=\"message broadcasting permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Message Broadcasting</h3>\n<ul>\n<li>One approach to keep track of the number of tokens used is for each host to tell every other host everything. ie tell everyone everything aka <strong>full mesh topology</strong>:</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 198px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/857abb0e72fa792e73a0e0a84a0e21ee/0780f/ratelimiting5.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 95.45454545454545%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAATCAYAAACQjC21AAAACXBIWXMAAAsSAAALEgHS3X78AAADBklEQVQ4y61T/U+SURT2j2qr1Vo1m605a1lTs61yc2ppZmY6zfzY1CVt/pCrrdVWfoCiEgICIciLAiphOvlQSJszh2ZqSCIoIk/3XuGdpviTdzvve+75eO459zw3ASe4IpEIEjweD0QiEVQqFaxWK4aHh6HT6TA2NsZ0juNgMpngcrkwMjICvV4Ps9nMdLFYzPI0Gg0mJiYYaEIwGITRaGQGmkRBDAYDxsfHodVqMTg4iNHRUbjdbnYgPYD+aYzFYmGiVquhVCr3AE+8ZfrZ3d2NSjgqRI/s2cLhMO8PE19sH8vbvz9QYcwQ7+QD/kh8PwOk1dA1u2SDoC8Xr1R5EChzmD77y84n+jbX0NxfQny5EJCYenkWjC4F89HOWMuxDV0Dji5USG7gzUApmnVPUdyZBL2zmwec+z2FIlES89GYCkkqPnBVzBc+CtDkVqBEfBUvldloJBVSXWuTgXYTJk1Me1wo6UxGveIemr4U4FlXMtrNjfErNExJ8aDtLATqXNQp7iK//RxU4118hfZ5OwraLqBWdhuvtUXIaz2DT0N1R1QYvUPHggUVPamo+pzBpFJyC7b5UYR2wGRxzUPu7T6xp6FGmolScQo0k8LDFe6fYHB7A8veZaysryBAdLo2AiH8+bvF9K1QAF6/F2sbXviDPr6Y42kTPkgNCrjqCx5LK57YNDNm2NzawNdZLTiHHAanAtYfOgSIzR/cgc+/jR1CYtu8GUPTChin1Rh2q7DiW/y/wsi+KfcRWlxGdS+5Q2kaCoUXwTnlfLUziy4Ud1whvnQW81iUiDZTY3zacFMSVPWm4x1XSaQc5T3XofjWvQdIZHLOTgZxDW/1ZXhveIFqaUacKUcBjS45CkWX0NCXRahxB0UdiRhwyhgY5eHMkhtPCLFrZZlo0uTjEelAaBbEBxxyyZDTchrPJTdR1p3CdJNbzl/+wtoMHraeZ74awsXsj6fQYmw4DBi7UK9/FTqHGP12IbR2EXuK65urPGBoZ5u9Jo2tncSIyF+In6vfo0PZpePFPwD1PqcidsadAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"RateLimiting5\"\n        title=\"RateLimiting5\"\n        src=\"/static/857abb0e72fa792e73a0e0a84a0e21ee/0780f/ratelimiting5.png\"\n        srcset=\"/static/857abb0e72fa792e73a0e0a84a0e21ee/27f03/ratelimiting5.png 173w,\n/static/857abb0e72fa792e73a0e0a84a0e21ee/0780f/ratelimiting5.png 198w\"\n        sizes=\"(max-width: 198px) 100vw, 198px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>How would each server know what other servers are present in the network? You could use <a href=\"#services-service-discovery\">service discovery mechanisms</a> already discussed earlier! However, this approach is not scalable. </p>\n<ul>\n<li>Another good approach is to  use <a href=\"#handling-failures\">gossip protocol</a> that we've already seen earlier. </li>\n<li>Another approach is to use a distributed, in-memory cache store (Redis) to keep track of the count for each server's used tokens. This will be eventually consistent but is highly scalable:</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 325px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/b344d249ce9f626768931b179a3c0ad6/d53b1/ratelimiting6.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 58.15384615384615%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsSAAALEgHS3X78AAACTUlEQVQoz4VT32/SUBTmH/PBbIlZfDBG5lgyo1PjEh+c8cEYFJeNOVg0yzTR+CMb2zTuiTlgkoxmkRVUQkAoIDLMFBBH2HQE7Q9aaD/b25VAXPQ0X3p6zr3fved8pyZFUUDTNCiKgs/nQzAYBBWgEIlEiB8IBFCpVKCZLMtQ1OdfZtLyoiSC4zjwPAeWZQkEgVffv8FyLERRJIu1wzUYfmfMgMlI/M8612m+rKIld6Clx0zagvd5P+bpCbhoO7arabIpW46S7/nNcUS3Kb1kRe665eElq7YQuoMJ7xBsK/3Y+OgmCT+ziLHVAdh9Q1gKOw9uJrfJdmsCorl9rL6r4PlGGa5ACTs/eINwEleXezH6sgehLa9OmFzGlRfH1VgflkL3ILcAQWyS3HqsikEngzN3UzBPMeh3JHHkegwjDzI6YaVWQLJII1UKo87/JJv22V0wxTAShbfYqZVV4QBWkJAv/8LgdArHbAlcvJ/B5YdZDDhTOGFn0GON64SaNUQBkiR29UOUGmpcJA1vSC3wDQm5Uh291hjMjjQuzGZw7VkO52fTOHojhuGZtE7oiT/F1NowJn1nEf/6hpBtfnoNu+eSihE170KzqR2gl/zEX4RlmlHLTaLvdgLnZlIYfZxFee+gh5qaYx4LrO6TbVHWkouwvTqNca8FC7SjLYphn7+ziG7VMLf+DcyXerfKK7FHuOk+hVtuMz4U9BuG816iugZfYq5rbGRZOWRO9fkkhA1JUEWoosbtqf3Sy2q2JBLTIDaFv/4OuWOoNd+Yzz+NE1LgIepm3QAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"RateLimiting6\"\n        title=\"RateLimiting6\"\n        src=\"/static/b344d249ce9f626768931b179a3c0ad6/d53b1/ratelimiting6.png\"\n        srcset=\"/static/b344d249ce9f626768931b179a3c0ad6/27f03/ratelimiting6.png 173w,\n/static/b344d249ce9f626768931b179a3c0ad6/d53b1/ratelimiting6.png 325w\"\n        sizes=\"(max-width: 325px) 100vw, 325px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<ul>\n<li>Another approach is to have a single leader in the cluster that'll gather information from all the nodes, calculate the total number of tokens used and return the number back to each node. In this setup, all nodes will only talk to one master node. This can be done using consensus algorithms such as paxos and raft implemented in a coordination service: </li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 159px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/9251fa7909bc861314a18f929d257159/06169/ratelimiting7.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 139.62264150943395%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAcCAYAAABh2p9gAAAACXBIWXMAAAsSAAALEgHS3X78AAAFHklEQVRIx61U+0+TVxjuP7NfluwXk7lkukSHmnnJppuyOLPolpigRi5RcTJaQEXByrWoFAtyp4VaUC6WcmmhoFAhyhABARkXFSi372tLr9/37JzzlRZ20WzZSd6+7znn+Z6+7znPe2T4n4dsaGgIg4ODmJycxPj4OKampmA0GmGz2TA9Pc32rFYr2x8ZGcHc3BxmZ2cxOjrK8BMTExgYGMDY2BjsdjtkZrMZer0eOTk5yMvLY3FaWho0Gg1KS0uhVCqhVqtRXFwMlUqFrq4uaLVaZGRkoLGxEUVFRSgoKGDf9j3tg0wURbjdbvgDfmI+krQIv98HQQjAR7zf70cgEGCeYgPr6wRPsYIoMDw1ui/7dyckvn+XEooERAPj83LktyWg0JLCTN2eiPYX+hBQEAQWP5u0Qt2WCI0lieEKzHLoenLhdPPSpdCfZX4B8boDSDR8h18N3+LS/YM4p/sKCTWHQkB6BHRkNkUjTrsbKQ+OIr5mP8EfQlTx53g5+zRMuMTPQ2GIxK3WC7jXcQUVT5RQPooia98TQk4iFCXCnOY4pNYfR1nXdRR2JKOoMwmxFbsw/GdCOSGkWSlqIyGvPcL+Pbn2hzBhMMM80wXEVEWQag7jysMfkUCqiWGEfWHCRW6OZRNfsw9qSwIym8/gfPVepNQdg2NtdROhynQesYRQ+egUqSQdF/UHEFe5h5RsCxNyrmVcqj6I02XbEVu5m9gunCrdhiTDUbi9rk2Et1ou4mTxVpJVBMvsbMUOnCrZjlfvBiRCeoN0DE4/gem3CrQM6mAc0JG4EiNv+kNyobg1j4hp+zjBVKH1hY4ZxfWMNROt+sMZrpP+k9wCgkjO2UMI/R/WYUhnQR7aK05Biql5vH4iKw/pDOEDkheDwg5mF1iZgW+yF57f++F8/RSBKRtcS3NYcfnpP4bSXnYsoGfUhN5XLbCNteLxqBEvZ/qwXqSUYcALvjASXPoWcMqtxD4Fd+0T8PrYYCkC62E6CtoV7MLiqvbgbPkOxFRGILo8Aq/nh8KEgscB7vZe8LoocHUX4Kz/BY67B+EoP/GXg80yRuN648+oepIBTYcChdYkRFd8iaGZDbIRvE5w+QfA5+4EX/ANHPciwWd/Ab7yJPg1PzinB5zDDdeaiGzjOcRX7yfdcgLXGn5CasNxJqFNwha8JEP11+Bvfga+5Bi4O/vA3dgChzYK3oBInisBXh95vsi95LXEkzJ3Ir3pJPJazzNySdibCF3gVBHgUj+WfNZ2rF7+aEPJtFwhVPLpsm1IrD1MHohjrF2jSraFS6a3TOHufi1cDXJw9Qo4GlPIOcrhHTZJVAK9FImwc7geNx+dQY4pDlnN0chujiEXJceqc2lzp6wPh0/S4n8ZQWGL5NB9WFz1YMXhxeSbZbxdcDAxL666ycPhxRKxjX49Xjf7qjfURTLe5YO2ZQZVphnm9ZZ51LS/g671Darb3uI+mVOvN0ueYcwSRtqfQ7lxBub+BYmQZlHWNAVVWTcyNW24piJnpDYhMb0KOcUWXM42IFX1EFdzHyC3tBs38o1k3oDMwnbcuNOMtNtNKKobhal3njWAzL7ihqp6Ahmlz3HlTicU2a24frcHSSryQZEN8mwTWbdCkdsGZckzpOZ3IVllQZqmF1fJerKqDVkVwzBY3jI1yNzeABq652HoXEBd9yIePF5GXRfx3UuotdrxkMxpTNfpvC4YUwyN6b6OlG8bXg7rMKw1ccPbJb5n/e9iafwBT3+Dd+WiM9QAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"RateLimiting7\"\n        title=\"RateLimiting7\"\n        src=\"/static/9251fa7909bc861314a18f929d257159/06169/ratelimiting7.png\"\n        srcset=\"/static/9251fa7909bc861314a18f929d257159/06169/ratelimiting7.png 159w\"\n        sizes=\"(max-width: 159px) 100vw, 159px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<ul>\n<li>We can also have a multi-leader setup where we can have multiple leaders coming to the same answer and then broadcasting it to their respective followers:</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 201px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/cfe4abc0b2fd0fa618d92de068254e94/51d3c/ratelimiting8.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 87.06467661691542%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAYAAADdRIy+AAAACXBIWXMAAAsSAAALEgHS3X78AAADPElEQVQ4y32U628UVRiH+4/4D/hJ/abxRjQCUWwoUVQSY+Jd6gfUaoHUSADTAq263rosUtLuUmYLbbllQbCktvpBAqtGg0Wj8KHddWd3O3NmZ3ZmdmYfz8zesm71JO/MOec959n38pvtsm0by7IIhuM44dzzPFzXJfAFo1KpUC6X8X2/uQ58wdowjPAd3AlGVzqdJhKJoCgKiUSCw4ejJJNJzp07y+zMDJOTk8Tj8fDM4uIic3Nzcj1BNBpFSSrEYrHwbiqVqgGDqPL5PJlMhkKhgCrnxVUNXRhous7K8jK5XI5sNosQglXpU3N5aSrFwirFYhFVVdE0rQakY1TBd6U5clpZw+vjeBaub2N7VruvWqUreFRlDSQGT5dRjD+PiG1GHH0affQJnKXL9dM+tmsxfL6XncnNvH9qK30nNjFzdTR0B3UMgTVyrdhe5hf0Tx5CnHgFY+oNxMcPUP4+RlhueaRgqPQr3Xw+10fs2wH2nNnG6JX+ZnSdwL+XEJF1iNHHEWNb0YfuxryaoCx9sumoosiuqS18MPsMh1Kv846ykbGFvf8DzN5AH7wLPfKwTLub1YE7cH441qyRsArsOL6e/pObGL6wne3x+4le2b0WsFqrQ1nDuriP0uy7GLP9WKf7MG9dp9Eap+IwNr+XA+dfZTjVy+DZF/nm1ySNoFrA2k74DsyVj5JT+5EAppdsKp7fFIHr2JRMKXTPbetwm2waG61LraUvfcJ0cFyv4cb6l1wa+20pm7ZgWspgbH4/x+aHGF/4kJsrP9ahPiVLfprXpzC/HkK/9BHW5YNUln/uTNmvN+VmJs2OyfUMpV6W9hJvKY8xsTjYCsUx0L/YIPUpVXB0C9qBezAv7KvL1OsE/pH9iV2nehi52Btqbfd0D8e/Gwk16HhVnJKGIUGB6EvKa4jPHsW8dPC/I/xdAt9WNrDn9LPSnuPNxINMLBzClkI0yh4lrYj4ciP6yH0Y49vQ998p0x+sR7gG8La6xHvJJ9l5spuB6ackcB1nrh1ppezZGPEX0D99BHGkR4LvlV/SV50pN3UowbdyN/ht5VpYz6WVNCVbb6UUnDGLePk/pf2FV7gt/z+ctk7/A1FmtwH1TInVAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"RateLimiting8\"\n        title=\"RateLimiting8\"\n        src=\"/static/cfe4abc0b2fd0fa618d92de068254e94/51d3c/ratelimiting8.png\"\n        srcset=\"/static/cfe4abc0b2fd0fa618d92de068254e94/27f03/ratelimiting8.png 173w,\n/static/cfe4abc0b2fd0fa618d92de068254e94/51d3c/ratelimiting8.png 201w\"\n        sizes=\"(max-width: 201px) 100vw, 201px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>Out of all the approaches above, we'll use in-memory Redis cache. Here're all the approaches that can be taken to allow server-server communication:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/af08bfc973f6cd6551f95672f3bd6185/ff38c/ratelimiting9.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 51.226765799256505%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsSAAALEgHS3X78AAAB3klEQVQoz42SW28SURSF55/5s3z0zTcTfag+1USpsdXEWzW1F7XEWCgiLS20IBSxXGRmmGGYYZgLc+bzMLTQxmhcmZ2drHVm7ZV9jqJrfQzdlGWg9XR832cKd+RiaCa6pqP3+rium/AiEsl5tacxMIbEIuYqlPagRrr6knJnny/19bkwDh02Syma/VM2So+YiDDhJ1HIVnmFhl5mq/QExxsgZ1BpOXT6HkrHbJCpbVJuF8g3PiwMA4d05RUtQw6svCCMgrnh5+prmnpV8m+locXttSY3bua4tVJHqfWKvCksk61vs3H0eG5oy8lr+3c57eR5mr1DMPESPpwEPM/dkwFysi9hjXUOz1xW011+qmMUL3QxXZVRYCX9EiKOMJwOXjhCd9qSme0qjmM0u40b2OiyTxNf26Hn+pialSzYtX2EEIkwHA7RzBF9c4htjLBt58KQPyDkxUSyhBSVunrMu2KKbz922T5enf0kK4oi/PR9rLMMzw6WUa3zC0ORpLxal8mnpajyUg6/v6fSPeBrY2cuTmGV1rF7J+SqsrvaNe1vUOgWIfuQYmuXHfkcFtMEqcIDTs734NMSYtCabTEW/zb81TPI7B3xMV8hV6ktUsjPcLp4vo2wVcQk+K+EvwHy++4COyl48QAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"RateLimiting9\"\n        title=\"RateLimiting9\"\n        src=\"/static/af08bfc973f6cd6551f95672f3bd6185/1dda8/ratelimiting9.png\"\n        srcset=\"/static/af08bfc973f6cd6551f95672f3bd6185/27f03/ratelimiting9.png 173w,\n/static/af08bfc973f6cd6551f95672f3bd6185/376d0/ratelimiting9.png 345w,\n/static/af08bfc973f6cd6551f95672f3bd6185/1dda8/ratelimiting9.png 690w,\n/static/af08bfc973f6cd6551f95672f3bd6185/bcbcb/ratelimiting9.png 1035w,\n/static/af08bfc973f6cd6551f95672f3bd6185/ff38c/ratelimiting9.png 1345w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>Now, in order for the servers to talk to each other, they have to use some sort of communication protocol. We have 2 types of protocols: TCP and UDP</p>\n<h3 id=\"tcp-vs-udp\"><a href=\"#tcp-vs-udp\" aria-label=\"tcp vs udp permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TCP vs UDP</h3>\n<p>A service host in a network has to choose how it wants to send its data to other hosts in the network. That choice boils down to sending the data reliably vs unreliably. Reliably, data is sent via TCP:</p>\n<p><strong>TCP</strong></p>\n<p>This is the most widely used protocol to send data between hosts. If there is a network blip and some segments are lost along the way, TCP can recover them ie user experience is not compromised. Here're TCP attributes: </p>\n<ul>\n<li>Slower than UDP</li>\n<li>Guarantees delivery of data</li>\n<li>Guarantees that packets will be delivered in the order they were sent</li>\n</ul>\n<p><strong>UDP</strong></p>\n<p>UDP has no error handling or sequencing that comes with TCP. UDP has one goal which is to send data fast! All the checks done by TCP are time consuming. UDP is chosen for live data transmission such as voice calls, live gaming etc.</p>\n<ul>\n<li>Faster than TCP</li>\n<li>No data delivery guarantee</li>\n<li>No order guarantee</li>\n</ul>\n<p>So which one should we use for our rate limiting solution? If we're more interested in accuracy and are ok with a hit to our performance, we'll go with TCP. If we're ok with inaccurate counts BUT want lightning fast responses, we'll go with UDP. </p>\n<h3 id=\"design-distributed-message-queue\"><a href=\"#design-distributed-message-queue\" aria-label=\"design distributed message queue permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Design Distributed Message Queue</h3>\n<p>Let's understand what synchronous and asynchronous communication is before we begin designing distributed message queues:</p>\n<p><strong>Synchronous Communication</strong></p>\n<ul>\n<li>When producer makes a call to a consumer, waits for a response.</li>\n<li>Easier and faster to implement.</li>\n<li>Harder to deal with consumer service failures. Need to think about when and how to properly retry failed requests? How not to overwhelm consumer service with too many requests? How to deal with a slow consumer service host?</li>\n</ul>\n<p><strong>Asynchronous Communication</strong></p>\n<p>Queue : Producer sends data to that component and exactly one consumer gets this data to a short time after.\nIt is distributed, because data is stored across several machines.\nDo not confuse queue with topic. In case of a topic, message goes to all subscribers. In case of a queue, message is received by only one consumer.</p>\n<p>Let's look at our functional and non-functional requirements:</p>\n<p><strong>Functional Requirements</strong></p>\n<ul>\n<li>sendMessage(messageBody)</li>\n<li>receiveMessage()</li>\n</ul>\n<p><strong>Non-Functional Requirements</strong></p>\n<ul>\n<li>Scalable (handle load increases, more queues, messages)</li>\n<li>Highly Available (tolerates hardware / network failures)</li>\n<li>Highly Performant (single digit latency, both send and receive operations are fast)</li>\n<li>Durable (once submitted, data is not lost, so persistent)</li>\n</ul>\n<p>As always, let's start with a single producer and consumer and a single machine. On a single machine, all we'll be doing is receiving a request from a single producer that posts to our queue. Our application sits behind a single LB that knows the address of our single server. Our single server would be connected to one DB that'll be responsible for keeping track of the metadata of our queue. For the sake of record-keeping, we'll save each message received in a separate DB that is accessed via our message service:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/4f750388e326118674095cd0265018f3/f4bb9/distributedqueue1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 31.62995594713657%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsSAAALEgHS3X78AAAAsklEQVQY02WRjQ6EIAyDef83RUGDgn+gu3xLduFOk6YbHaWgO45DDOd5frm1Jvd9K6hZ3/dd2dYM9LVWua5LXEpJQIxRMc+z9oi9wbZtwreuq67D4zjqnmVZxHsvwzCIQyyl6EYYQ4YxhRlGo0fPOWsqDgghyDRNqsPAkYQrEpkhS0CNAUCDSdonJB0mPwkRgJ3A5ud5Xm9k78xBzNiNAIGsdlYwSFqGe6Pe+F+jB/bzwAfju9ItgSNjOwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Distributed Queue 1\"\n        title=\"Distributed Queue 1\"\n        src=\"/static/4f750388e326118674095cd0265018f3/1dda8/distributedqueue1.png\"\n        srcset=\"/static/4f750388e326118674095cd0265018f3/27f03/distributedqueue1.png 173w,\n/static/4f750388e326118674095cd0265018f3/376d0/distributedqueue1.png 345w,\n/static/4f750388e326118674095cd0265018f3/1dda8/distributedqueue1.png 690w,\n/static/4f750388e326118674095cd0265018f3/bcbcb/distributedqueue1.png 1035w,\n/static/4f750388e326118674095cd0265018f3/f4bb9/distributedqueue1.png 1135w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>Here, a single producer produces a message and sends it over to our virtual IP address. This virtual IP resolves to our single LB that then forwards the request to produce the message to our API gw. API gw then checks to see whether the user is authorized to publish to the queue and upon successful authorization, allows the message to move on to metadata service first. In our metadata service, we check to see whether the queue being pushed to is already created, if so, we return the name of the queue back to API GW, otherwise, we create this new queue and return this information back to our API gw. Once API gw receives this response back, it will call the message service where it'll hold the message for the queue. For durability, we'll also store this message in  message service's DB. </p>\n<p>To improve this experience and add reliability, availability and higher durability, we'll create a distributed service. We'll start by addressing the first point of failure in our architecture: the load balancer.</p>\n<p>A single load balancer would be overwhelmed if there are too many requests. Therefore, we need multiple load balancers using VIPs and have these load balancers partitioned so that each LB can receive a request and forward it to our API GW:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/f56a2e30586ec9e93f3b52e057e3457a/bb585/distributed-queue1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 53.125%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAACWklEQVQoz42Q2U8TURTG+xcafTEkanwQXjS+EFyCJrLVBwTZNzVGiYYHCAEaYChFUDaLaAcjUKAspRvLtJTOQjtl+vPOEJbEF2/yy3dy7z1fzvlchYLFJQUHKKBksqzGVTb2ddYFvyMawYSOkbO4es57zvrAxX8f0yFv5TBPs4LchclVc9fJocyJ8gdb83qCbNYkFo0SCm06WHmLmBKic7SKN1IN77xuoVV0T9aRMVL2MpimiWWdTe7aku6zM/GYsO8h2mY/6aM0fb29NDe10NnZRebwUBgGqRsopWGojEbPI+oHS2mXnnNsJMkcqyQSCTRNOzMsaOsgKKhrFPS4c5lOp1EUhWQyiYiWtK4wuywxuzLG3KqXGVH71yY4yenOf3u68xxdp7ZB5uTsIW+K8XMYhoGqqg72Shk9xeLGFD9D3xzsWt6eJWsa/2ZoZXWSC0PYo+SNDKmDhFi5j6bGZjo6OlGVJDt7Szz5WET5p1s8+3yLp91FVPcWc6QfoKsGe/t7lyvraQV1tgddU8XjsTNdMBhEDsjI8hKayGg7vkrXSA1vR92Cl3QNV/PBV8dBKiG20EilUqgZ1el17e7uEhY4uhUiHA4Tj8edoG2NRmOEtjYILC9c8Esgr/xge2eLWCzm/ItEIo6HKxAIYCPLMov+Oaa++GhtaaWiohJ3jZv56Wm8UwOUvr5NWeNdh9KGO5S3lTDj/8r83HcmJyfx+/2Oh8vn83HB+Dg+r5f2tnZqa19RX1+PNDxCT9977r24RknFdUoqb1As6gfumwwO9yNJY3g8HqGS4/EXFI4BO+mkedgAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Distributed Queue 2\"\n        title=\"Distributed Queue 2\"\n        src=\"/static/f56a2e30586ec9e93f3b52e057e3457a/1dda8/distributed-queue1.png\"\n        srcset=\"/static/f56a2e30586ec9e93f3b52e057e3457a/27f03/distributed-queue1.png 173w,\n/static/f56a2e30586ec9e93f3b52e057e3457a/376d0/distributed-queue1.png 345w,\n/static/f56a2e30586ec9e93f3b52e057e3457a/1dda8/distributed-queue1.png 690w,\n/static/f56a2e30586ec9e93f3b52e057e3457a/bb585/distributed-queue1.png 992w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>Next, we need our metadata service to be durable: ie our queue metadata needs to be replicated among various nodes. For this, we can either use single leader replication, multi-leader replication or leaderless replication. We'll use leaderless replication so that we have multiple nodes available to receive our metadata and distribute it among all available nodes. Single leader replication is not scalable since it introduces a SPOF: the single leader. </p>\n<p>We also want our data to be partitioned among nodes. Now, if our data is small enough to be stored on a single machine, we'll have every node in our cluster hold this information for us. So, when a request comes in to our metadata service to fetch information for a particular queue, we can send the request to any of the nodes. However, if our queue metadata gets too large, we'll have to partition this data using a hash ring with virtual nodes. To determine where each data queue metadata lives, we can either use client side discovery with each node updating a registry with its information or have each node ping every other node its information (gossip protocol).  </p>\n<h3 id=\"design-distributed-cache\"><a href=\"#design-distributed-cache\" aria-label=\"design distributed cache permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Design Distributed Cache</h3>\n<p>A cache sits between a service and a DB. Our questions deals with designing a distributed cache so that we can reduce the number of calls to a DB (which are expensive). Therefore, storing data in memory will help to address these issues. When a client request is received, we first check the cache and try to retrieve information from memory. And only if data is unavailable or stale, we make a call to the DB.</p>\n<p>And why do we call it a distributed cache? Because amount of data is too large to be stored in memory of a single machine and we need to split the data and store it across several machines.</p>\n<p>Let's start with the functional and non-functional requirements:</p>\n<p><strong>Functional</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"cpp\"><pre class=\"language-cppcpp\"><code class=\"language-cppcpp\"><span class=\"token comment\">// Stores object with a unique key</span>\n<span class=\"token function\">put</span><span class=\"token punctuation\">(</span>key<span class=\"token punctuation\">,</span> value<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">// Gets object from cache based on</span>\n<span class=\"token comment\">// key provided</span>\n<span class=\"token function\">get</span><span class=\"token punctuation\">(</span>key<span class=\"token punctuation\">)</span></code></pre></div>\n<p><strong>Nonfunctional</strong></p>\n<ul>\n<li>Scalable</li>\n<li>Highly Available</li>\n<li>Highly Performant </li>\n</ul>\n<p>As always, we'll start with a simple, single server design first and then evolve our solution. If we have a single server, we'll have the following setup:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 38.19444444444444%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAACE0lEQVQoz02N70tTYRiGz18jBmZJiJJkiZChpkYgZZYoGdbEyi/SB/3QR0FKwanZRKxkLidEo7BME7Odc+aaHo9uc9PUzdwU1i9Tt5O7Og7RXri43vvlfp5X4ODE4/GEAz98SIERnGtjOIMf/mMMWX9f/7Vy2D8Y4WgHCG6fn99bW7AHP/98p95WyI3BNCqtGVQMZh1SNZRB+ctUmt5fIxqNomka8b8asViM7WiMmBbTd2gIals9kY11dnY1gpvL3LRk65ykxNxKrmWB8xanbi+l5gdUDqRw71UR4UiYvd0dBubCGD6FqBM3uDsZ4oUSQvB0N7IeWGYzGMC3pFDVn03F8+Pk9fZx6rGL9JZ3CRc9a+Z6XzJ11mKWvnrZDq1w/80CSS0TpD8aJbVd5rZtEeFzTRYL4ihr38KoXhcVvWco70kh72knmV1uTnfaE75oaqLMlIyhvxCPz01kbZXGt3OcaJ0ks22cDKNEg20ewTVkQhXH9V9XcSoSpcY0LhuPUdyeQ4GxjMKOK+Qbr3LJmEVJexKVpnPMziss+v04VTevZTdW0Y1NnselehBmvX4UdQ5lZgbXtIuH5lpudV+gtiefmq4cqjvOcqc7F4OpgOoneTRbG5hVVKb1vqrM4FWVBB4dVVEQRLsdSRSRJAlZkplyOBH17HBMMTw8gsUyyMfxiUTe70w5vuiWE3dRxy4esZ//ARe37YTDepJQAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Distributed Cache 1\"\n        title=\"Distributed Cache 1\"\n        src=\"/static/9d0d7d665d1477fe47eb86308e4c2751/1dda8/distributed-cache1.png\"\n        srcset=\"/static/9d0d7d665d1477fe47eb86308e4c2751/27f03/distributed-cache1.png 173w,\n/static/9d0d7d665d1477fe47eb86308e4c2751/376d0/distributed-cache1.png 345w,\n/static/9d0d7d665d1477fe47eb86308e4c2751/1dda8/distributed-cache1.png 690w,\n/static/9d0d7d665d1477fe47eb86308e4c2751/91043/distributed-cache1.png 720w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span> <a href=\"https://www.youtube.com/watch?v=iuqZvajTOyA&#x26;ab_channel=SystemDesignInterview\">Image Credit</a></p>\n<p>In a single server setup, the client makes a request to our single server that has the cache implemented locally. If the request comes in and it is a cache miss, we'll get the data from our DB, store it in our cache and then return the value to our client. If it is a cache hit, we'll simply return the value from our cache. In essence, this is a read through cache system. Let's dive into various algorithms that can be used to create our own cache. </p>\n<h3 id=\"lru-cache\"><a href=\"#lru-cache\" aria-label=\"lru cache permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>LRU Cache</h3>\n<p>We'll be using a doubly linked list to keep track of all the requests that we've received from the client in a linked list in memory. We'll have a tail pointer that points to the end of the list. This pointer will be used to evict items from the cache. Next, we'll have our linked list setup so that every new read would cause us to move the item we've just read to the front of the list (since we're using LRU as our eviction policy). The linked list will allow us to:</p>\n<ul>\n<li>Keep track of least recently used key in <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(1)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mclose\">)</span></span></span></span> time via tail pointer</li>\n<li>Move key to front of list in <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><mi>N</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(N)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">N</span><span class=\"mclose\">)</span></span></span></span> time (we need to iterate through the list to find our key)</li>\n<li>Adding key to list in <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(1)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mclose\">)</span></span></span></span> time (using our head pointer)</li>\n<li>Finding key would take <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><mi>N</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(N)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">N</span><span class=\"mclose\">)</span></span></span></span> time.</li>\n</ul>\n<p>We can make an improvement here: we can have a hash table that holds key and value from our linked list. When we add an item to our linked list, we do the same to our hash table. When we remove an item from our linked list, we do the same from our hash table. This would allow us to return items back to the client in constant time and then update our list accordingly. Here's the LRU cache algorithm decision flow for GET and PUT:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 44.14739884393064%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsSAAALEgHS3X78AAABR0lEQVQoz21Ry47CMAzM//8OB04IhAQCCcGFR1tUuANNW5aljzxmbUMKy66lUZKxZ+wkCs/w3sta1zWstR0XeOcciqIQaK2l7l3btq3sVRCE9Xr9gjHmX8NrWZJZLggGHMZYalS+DIPoIez6wn9MH8SfwWn3LFEvI0ekR9W0aM3vKwc4UtVveffsbuiJqroVvbrdbqiqGk1jqNAhzzW+73d4/A1LhiVdu6L349qGzI31uJNe64z2Doo/gMHuljpyd4ZM/AFrH3m+Nu8DzxM25uGjws/leS7r6XyRBw5c4Hkyxul0ljN/UNBmWYZLpiWvjscjApIkwXq9QRzHOBzSjk/TVLgkibHd7RBFkYDrOR9FMTbbHfb7PdRyuQRjtVphPB5jOBxiNpthsVh0/GQyQa/XQ7/fF/B5Op1iPp9LDesGgwFGoxF+AKooru/AlLyVAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Distributed Cache 2\"\n        title=\"Distributed Cache 2\"\n        src=\"/static/77d41d62d24b8002ea60152181c14b5b/1dda8/distributed-cache2.png\"\n        srcset=\"/static/77d41d62d24b8002ea60152181c14b5b/27f03/distributed-cache2.png 173w,\n/static/77d41d62d24b8002ea60152181c14b5b/376d0/distributed-cache2.png 345w,\n/static/77d41d62d24b8002ea60152181c14b5b/1dda8/distributed-cache2.png 690w,\n/static/77d41d62d24b8002ea60152181c14b5b/bcbcb/distributed-cache2.png 1035w,\n/static/77d41d62d24b8002ea60152181c14b5b/b4b06/distributed-cache2.png 1380w,\n/static/77d41d62d24b8002ea60152181c14b5b/6da63/distributed-cache2.png 1384w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span> <a href=\"https://www.youtube.com/watch?v=iuqZvajTOyA&#x26;ab_channel=SystemDesignInterview\">Image Credit</a></p>\n<p>Next, we can go ahead and discuss the LRU cache algorithm code in detail. Now that we've explained how the algorithm works on a single server, we need to make it distributed. Earlier we said that this is a distributed cache because our cache data is too large to be saved on a single machine. Therefore, we'll have our data sharded among different hosts:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 481px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 103.74220374220376%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAVCAYAAABG1c6oAAAACXBIWXMAAAsSAAALEgHS3X78AAAD0ElEQVQ4y32U3W/bVBjG/RfAxDXjCiGugLG7MS4AcbldoE2bxDa4YNs/gIQYXHCDBGhIXKAxuADER2gLSqMlqUSbhBaG6NjSJG3StOuaLztuE9uL48R2/JE8vOckdtdWwtKj8/p9f+c5r4+PLYxGI7BLN3RU61U0ZQnblW00xDrPsYsxAWfaJqq1CiTi2FitVdFWWiEnDIdDigDPGqElqni420Vb0tBuavAt8BpjuOmQblygJanQdnQo8kPODgyPc77vQwD5ifo2fih8gkjpOn4uXucj04+rn6KpVznMzDqmiqniF8R8hsiE+6X0Ob4vfIwtZRXMS2Ct/lWL49xvz+LS7Iu4GH2B663Z4zj76zNYbvyO8fMAW2oBb8eO40L0eWKOhdyZmacR3/iWY6HhpdljuBI/icvxl7iuUnwh+tw+w/tKntfeuXViwp3A1cTLeJO4xOZ3E0MCS607eC/1Bj7InMO11BlcW6D4j/M8V25nx4b0OHK3ho8WL+L9NDHps5z9MHMe7y6cxrI4XlhgG+l5HsxBD/2Bgb5twOjIXCzn+UP+Upg8z4flmMT10Otr6BkK+k6fc67rTV7K5HWzTkOxwXXg9XX4joXgGk1ORFAfDqxwO4JjJQRBcNZCTXL+oA/P7GLke3sc2wHXppoZcoHxXof/czEzz6Ru7V7IjjyHurQDImxkX4cu7SWTN9G4trfY0B3QNnTg0Nfi2BYc0wj3OPxSAkPLsnDv3l0U8nmsFgoorq3Btu1Dnx5bKH93GSu30yiu/IvsSg66vveJCj7rynUxpNGnBFvLZ92wmHKO4/C3x7pgMcsNubELn3J8Dm2JQx5sMcFxx5u90PLw2q0KTsW3cDqxjVeSDSzsuvyRXTJ0PZ/Ht1UPryeqOJUcs68m64g1He4xIC/Bsge8p59qNo7czOLoV//gqRt/47Gvc5Rjx8Kjs+fCdhwexyQbT3yTw5M37+Dol3/icZpz44HFPUzyErrdLh1QA+1OF0XVxHrXxTr9PVjc1umQU92gutHr8VihXIlzDmcZt9sZe+hUFzSNflWKAk1VYKhtaOslKNksursyNE1Fu001YpgUximMo7G4Bq28Pp5D98xDVVUIsiwjkNSU0di8j0apDFEU6Wcro9lsHpJEqpc30dh6wJlHPYRKpYJHVa3XUW00IEoiN2WSJCmMmRpUb+7sQCTjg/OFcrmMgyoVi5iZmUEkEkEsFsPU1BTm5uYQjUaRSCS4pqenMZdMYmNjY99cIU8H+aByuRwymQxSqRTS6TQfFxcXecxGpvn5eSwtLR2a+x+JuOAd+DHWwAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Distributed Cache 3_1\"\n        title=\"Distributed Cache 3_1\"\n        src=\"/static/fd232cb4c707d116e90a00b5d8394106/2210a/distributed-cache3_1.png\"\n        srcset=\"/static/fd232cb4c707d116e90a00b5d8394106/27f03/distributed-cache3_1.png 173w,\n/static/fd232cb4c707d116e90a00b5d8394106/376d0/distributed-cache3_1.png 345w,\n/static/fd232cb4c707d116e90a00b5d8394106/2210a/distributed-cache3_1.png 481w\"\n        sizes=\"(max-width: 481px) 100vw, 481px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span> <a href=\"https://www.youtube.com/watch?v=iuqZvajTOyA&#x26;ab_channel=SystemDesignInterview\">Image Credit</a></p>\n<p><strong>We need to figure out how we'll decide which cache client to call?</strong>  </p>\n<p>How do we decide the method with which we'll be distributing our data among cache hosts? We can use the following two approaches:</p>\n<ul>\n<li><strong>Key based partitioning</strong></li>\n</ul>\n<p>Here, we'll have the data partitioned based on the keys. We can have dedicated shards that handle keys from say Aa - Ba, Bb - Ca and so on. The issue with this approach is that we can have hotspots if the requests are not uniform, resulting in some shards being queried excessively while others sit idle.</p>\n<ul>\n<li><strong>Hash based partitioning</strong></li>\n</ul>\n<p>Another approach is to use a hash function that uniformly distributes data among shards. This helps get rid of the hotspots issue with key based partitioning. However, now, what would happen if some of our nodes go down? We'd have to re-assign data to nodes and this would cause us to unnecessarily move data around.</p>\n<ul>\n<li><strong>Consistent Hashing</strong></li>\n</ul>\n<p>We'll stick with the hash function but will use a ring to assign our data and servers. We'll also use virtual nodes to evenly distribute load across available nodes. This allows us to re-hash a much smaller number of values if a new host is added or an existing node is removed.</p>\n<p>Ok, so we've chosen the method we'll use to actually place our data on cache hosts but who or what  does the consistent hashing calculation? Answer: a light-weight cache client that resides on the service itself:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 43.26123128119801%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsSAAALEgHS3X78AAABvUlEQVQoz4VRy07bQBSdz+mGTT+mEiugiwqB2g0b1kh9RGLLEolKLYtWCNF3F02JVKwgZCkhkdzYSQQk9rh+5Ok02K59OvcmQmwQYx+d43uur87MiDzPQYuYH/qmN5/VsrlP67a+awn6M7+n8WMrxIHps44mE4xGIwyHQ/T7fWbCYDDARHkiyzNurLoaXv56glc/1lE4XkNBW0W7Z7C3UZZYO/nD2g9C2LYN13URhiGCIGCm4VmWQUyDK278ZOxi8WABK0cP8fT9EjZ39lBrt9kr6C62zlzWnu+j0+nAVxxFEcbjMTOlTtMUYnJV48bPv/fw6N0DLH1YwOr+Mp49P8R545K9bV3ixZlkHag0lM5xHEgpeXi324XneUiSBCKfb9kZXeCL+Rrfm2/xzXqDr9Y+gr8ee+vHF3j8szPb8nwgJaJkdHYEOsfpdAoRxwmu42tk6ex2kc2hdJr8U/UEp26EExkhT2OVykWz2eShdH69Xo+3TxzHMQTFJjjSge10FewbSFVzlDf0VSIF0o1GA9VqFZVKBYZhoNVqwTRNWJbFc0S9Xsd9OK/NQLpcLqNYLKJUKjETNE2Druvs/wfMZI730Woh8wAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Distributed Cache 4\"\n        title=\"Distributed Cache 4\"\n        src=\"/static/36be7ebdd7b03349cabb50ea51e51ad3/1dda8/distributed-cache4.png\"\n        srcset=\"/static/36be7ebdd7b03349cabb50ea51e51ad3/27f03/distributed-cache4.png 173w,\n/static/36be7ebdd7b03349cabb50ea51e51ad3/376d0/distributed-cache4.png 345w,\n/static/36be7ebdd7b03349cabb50ea51e51ad3/1dda8/distributed-cache4.png 690w,\n/static/36be7ebdd7b03349cabb50ea51e51ad3/bcbcb/distributed-cache4.png 1035w,\n/static/36be7ebdd7b03349cabb50ea51e51ad3/07dc3/distributed-cache4.png 1202w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span> <a href=\"https://www.youtube.com/watch?v=iuqZvajTOyA&#x26;ab_channel=SystemDesignInterview\">Image Credit</a></p>\n<p>Each cache client needs to keep track of all the available cache server nodes. To do so, it'll have to be able to know the exact list and addresses of each of the available nodes. To keep track of that, we have a few options that can be used:</p>\n<ul>\n<li><strong>Configuration File Method</strong></li>\n</ul>\n<p>We can use a configuration file with node information and deploy it on every service so that each cache client on each service would know exactly the server IP addresses and ports. </p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 325px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 144.6153846153846%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAdCAYAAACqhkzFAAAACXBIWXMAAAsSAAALEgHS3X78AAAE1ElEQVRIx5WU61PTRxSGf38KCR+wndpOTUAqEOzXTj9oxTpSFMIlIYpQSnUiMNNaIdiL4oCoQKFVQRHIhdy4Q4AAQ7lIZZhB2jiEBCkMgiAgUpK3ZxfCxTItJvPm7Nk95zlndzYrgD5e+nLr9cD38Xg88Hq83HrWtsk359mK9Xq9m1ZYHxFgA+aYGcZ1+1fItiVAY1Mgp0OJ77vWdaVTCU2bgqREli0e9wdzsbK6vAMqbHdW/n4Fdf1xROreQ2xNEGJNQTjxy4c4cn0/jubtR8StDxCtC4TcGIhY40F8XrUP2qFb6zvyrm116Otucn4cSmMYEs0yUjhUVhliKg7ixM0DOFkkQSRJYTyEREs4zlg+hrwmEFc7kuFj7ApUmQ9DYQqF0hxKyTKcrfkMSaYI0jEkGY9DZfiU1kN4wWiDBLn21P8GJprCKSEM8WYpMh7moPjBU/xc9QQl1X+QHUVB+WMk605BaQkmoBTX7F/+P1BpktH5SZBVUYbCOw5o8huRk9eMa0WdKL43jrSqVCRYAxGtD9wrMAxxJim+LS9BXtEIUjJKkZp5F+kaLW6UPkVq5Tko3gbIthxHW868W4IfC4ahulCEM+eLcSFLh59ujyLl4VsDZfwM1SW/4kq+E5fzB3EpdwCX8wahyRtD8oMUKGvfskOFJQhJZalQ5zdBXVCHiwX1uHijARcKDEjUHkWi9RABpXsFhvBzVJqCSYfobpJv3LCmj/jc+rU5sHegwhwGeW04YutkOySvozmrbPMe7gmYQJc6SR8CTbEU3xVKcalQQlZCVors2xJ8cyeI7uEegSoCyq2hyLgfDEe8CN1fiPBblB96okRoPSnCUKQI7eoAxNceRox+ly2znzeBsQS8SMA/VWLYo0VoIWC3XIwGgg7F+MGW+Q7irOG7A3fr0Ad8qvKH/bQItlMi9MipQxo/pgKtmft27ZA/X7zDjcdy8sUWUF1OwLP+GFaK0REjRstpf/Ql+MOpEKMtnYDUYTQHbjwOno3na3V1Fa9fr4CeM7hmHFDqQ+l/LIP6bjBcCWJMkH6nDgeixBij8V9yP5Rnvos4C3VYLcUPtiSi0VtKDMYSlpaWsLi4iFfLrzAzN40U/Sc4Ufk+EsskuJkdwFWUE4BiUqEmALnkx9w7gGjtQUSUBaC0OwdrK8DLxQXOEebm5sA0OzeLpYVldD1pRLrpJNKMx5BsOU6KwDkmcwQfp9DceXof0wxHcLX5a7innFiYfwkfR5iensaWpvDi+QKmp6Yx7h6D2+3cVa6Jdc3NzOP5zCy2M4SJiQlsl8vt4vbZs8kdmnzDZ3JTrNvt3pEvjI2Nwel08gWXy/Uv69P4+Dif80FcG9Y3z2IYS3A4HHj06BGamprQ2dmJ9vZ2WK1W7re0tKCxsREdHR18jfnNzc2or69Ha2srj2HxbW1t3B8dHYUwMjKCnp4eHmiz2XhwbW0t9Ho9hzE1NDRwGLMmkwk6nW7TZ3lGo5GPBwcHIQwNDfEkg8HAK7IEJlaxuroaWq2Wd2yxWFBXV8cLMbGirDhbZz6zrDGhr68PAwMD6O3t5RVYUEVFBYeyIpWVldwynyWxImzM5tmY5bI8dmz9/f0Quru70dXVBWaZ7HY73zo7F2ZZp8z6xLbKzs23xnJ9Yvn/ALVXFSeoFeoOAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Distributed Cache 5\"\n        title=\"Distributed Cache 5\"\n        src=\"/static/406cf4c0477cdc49e841e7d7fd7d0ed8/d53b1/distributed-cache5.png\"\n        srcset=\"/static/406cf4c0477cdc49e841e7d7fd7d0ed8/27f03/distributed-cache5.png 173w,\n/static/406cf4c0477cdc49e841e7d7fd7d0ed8/d53b1/distributed-cache5.png 325w\"\n        sizes=\"(max-width: 325px) 100vw, 325px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span> <a href=\"https://www.youtube.com/watch?v=iuqZvajTOyA&#x26;ab_channel=SystemDesignInterview\">Image Credit</a></p>\n<p>This is a simple approach but not very scalable. Imagine the amount of times you'd have to re-deploy services just because a node was removed or added!</p>\n<ul>\n<li><strong>Config file placed in shared location</strong></li>\n</ul>\n<p>In the previous approach, our issue with it was the fact that we'd have to redeploy multiple times just to update our host list. What if we have this config file in a shared location and just have services read from this shared location:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 343px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 117.20116618075802%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAXCAYAAAALHW+jAAAACXBIWXMAAAsSAAALEgHS3X78AAAEeklEQVQ4y4WTWXBTVRjH76Pjk04VH/SBwIyKw7gMu6OMOj64jBShA5gCpQFKV9oOIEuBAWQpw1LUKouoM5rCKG1IGjpFaQqFJqVBu8Vim2ppS5OSdKfpknuT/jy5aaENjp6Z39x7z/f/f+c75ztXGh0dxfDHGbLLEjlWnkFORQbHbYKKTLKvJZFf9zWBoEJoFDfoOaTq0sO6MW12WRL66qOMKMNIzV23ibs4m/hLs4n+4nnez54mmM6SUy+iK5rDyvxXae6up2+oi3XG14VuFktPz+C9gxrBNJacfAGdeS6f5M+kqv06UqO3hgTzGyQVvUXKeS0pP8apJJ/Tklz0DjrjPJydtXT5OthQuJDEooWk/ryClB+ETi90ebEkX3qXeNNcKttKkJzeOtaZ55Bm0HJS/yen9PWcyrvNmfN/kW7Qscb0Ck2dDrp9HrHwApIvfsyX+ipO5zUIXT1nz7eyqSCV1aaZ2NuuhhOuNc9SzUdy7aTvOEtG1ncczq1gkyGVOOPLDxKuN88jzajlUO41Nu/Ss3HHNxz+vJKtBVtZZXxJJCxFavI6whUW6Nifc5OEzFwyd+rZd9xKRn5KRIXzSb2oZU/OVdK2fU/q9m/57Fglmy58qlZ4K1Rhg6dGHOprpOSvYm9OPdsOlqvsyXGQdiGB1caZNHpq6RzoYG3hHJIMMew+cYusbDtbD5Sx91gD6T9lsNI0g4qWK0ihlTdfXsQaw3wS89aRkpeukpiXIOYWkFn8gdqQ0JXYWbKCOMNsEs/pSNYL3Tmh0yeiM7wpGvM2rT2NSKH71TngptZtxeEto9ptobrDIt6viblyPPfbGR89g17q3DYcnuvUdJRS5bKonhqhc/XdUTVS6GL//xgdI2IEI1Qil1phcDQo/oaA+vTLMrIiExgNjDmCKLKCLIf+lvBcSCsrCsN+v0jy0KtWODF7aMiKEAfCwZL2QTbe6mFLbT9bHD7SfuvF1DKgxhShGfErD7zj9T+SUBEJfSOyWk1W9X0eO13H1K9uMPVoMY+fcbCholeNDQzLYjfKJO+DMxxnPOhXwlvdXuNDOmEn6mgJT+43IR25wfrK+2psRCw80TOOFHmo4TMNf5e6h1llaSfG7CTmiotYi4vCtsFJmsimTqowkok9DgQetjT4Hx5JDnU1AkV9ii4K/GJrQyN+lVDDhsc6rvyLL4Q0ODjIJHwDDMkBup1V1O6JxpoVzc1dgp3RXN+xmLrdH9JVbxOaoKqN9Et9fX1MpLenm/4hP+7fLdi1UzAvfprLS5+hWGBaPIXKZU/gshXSL7oc0kb6Ja/XyyQ89+jqG6DVfgW7ToNx2VSMyzX8GquhYJmGm6ufo6W8kK5+n6qN9Esul4uJtN+9S0dnN03WYiriNfyiFUmXT+PSCg2XY6djW/ksTZYLuDt7VW2kX2ppaWEid5r/ptXtob7UyI3lUZQL8j+KwrjoKazivTQmCoeItbnvCW0zkX7J6XQyicZGmprv4LBZsB6MwyaozF4jiMe6T0v52QM0Opt4xDfGPx0f6c3DJNGRAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Distributed Cache 6\"\n        title=\"Distributed Cache 6\"\n        src=\"/static/9ea182748789a55ee12071a0271cc611/c0191/distributed-cache6.png\"\n        srcset=\"/static/9ea182748789a55ee12071a0271cc611/27f03/distributed-cache6.png 173w,\n/static/9ea182748789a55ee12071a0271cc611/c0191/distributed-cache6.png 343w\"\n        sizes=\"(max-width: 343px) 100vw, 343px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span> <a href=\"https://www.youtube.com/watch?v=iuqZvajTOyA&#x26;ab_channel=SystemDesignInterview\">Image Credit</a></p>\n<p>Again, the issue with this approach is what if this update takes time and our service reads an old file. This would result in a cache miss. Another issue is that we'd have to manually update the file.</p>\n<ul>\n<li><strong>Service Discovery</strong></li>\n</ul>\n<p>We can use a configuration service such as Zookeeper that'll keep an eye on the available cache servers. To do so, periodic heartbeats are sent to each of the cache servers to determine their health status. Next, when our service is about to perform consistent hashing calculation, it'll get this information from Zookeeper before sending data over to cache servers:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 478px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 77.61506276150627%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAAsSAAALEgHS3X78AAAC9ElEQVQ4y6WSW0iTYRjHv6sI1oHug9QLb4LuIrqNCq+isC4Ls5OZREHkRREeMqNBHjZ1zUhspfM0dVmieYBC5szUaXM6UdysueXWDm5u+07/3u/9Jmyu6KIXfjzP9/K+/+//Ps/DIGmJokihOccCWyEguikj5UmIbAxi0p1tmDRBQaB5aOYzLOoSmFVlmNFUUOYbn2JWW4kZsr8xYqDnBHKemviXYHisD5aym+grzsfwg+sw3svDh+IreF98FVOlN+A3vkxcks8LCQ1mp2UxcSBun0Kgqw4OvRqujjos6WoI1Vh+Wwtfuwpbk0P0nC3I4Uz/Kk63fsXF0R+yoCDyqQg8RKQunsAmbEghRnMRQ+449qlM2Ffei8zX1tQn71ySW6lGcZajNWJJjMc5uscL8i9HPSz2NC9BoTIjo4s49EbcMFi16JirR+dcA0GD9lk1Vnzz8tOJiLDdeRI5jicI4HjZboDY1q+xaFqNo8fFgTHONyG3MwvntNnIeZaJs5psnCfftab79AIrjU9CTFqSkEDcUUHi1E3errR4UT62ijrrLzC9tkZc6jqGxx1aPNHrUNmmwzVDDmrG70olIu6E1PmkP+HB028RH9dj2K2awK6SXhxsJjXsXXiBvM4TUNaZ8ajCiOcqCwrb8lA1XiQ3gDQpeQrk2RMRY3maD5MaKhq/QaEcwSH9CphuWwMud55CqdKE28WtKK2cRIE+H9XmbUHiMK3npLYcTx06IjzuTIdRYPLioTUKpt+uQ27LYdxqqEJhTT2K1Bpc0B1H/YRcQ17gkD6rotxpIhomDXrn3ETbkh+D38NgfMENjNgNGFh8g0G7ntCCgYVWrHlXwJERiUa3CNE0IgTEoxhwhrCXzKGixICMJguYUHATbEQgiIko5+FQBP6AH4FA4I/4/AHw4SB67D+xv/oTDpR1I+vVNBi32411tysFF0Ha93g8f2Xd7UFww4PRJReOti/gSNMXnDQug3E4HPgfnE4HbCurmFt2YJHE3z8taGvJMmWEAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Distributed Cache 7\"\n        title=\"Distributed Cache 7\"\n        src=\"/static/5349fc404fc5d690991dd30f4507842a/c78d4/distributed-cache7.png\"\n        srcset=\"/static/5349fc404fc5d690991dd30f4507842a/27f03/distributed-cache7.png 173w,\n/static/5349fc404fc5d690991dd30f4507842a/376d0/distributed-cache7.png 345w,\n/static/5349fc404fc5d690991dd30f4507842a/c78d4/distributed-cache7.png 478w\"\n        sizes=\"(max-width: 478px) 100vw, 478px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span> <a href=\"https://www.youtube.com/watch?v=iuqZvajTOyA&#x26;ab_channel=SystemDesignInterview\">Image Credit</a></p>\n<p>The drawbacks here are the operational costs of using a configuration service BUT this is the most efficient method. </p>\n<p>Now, every time a host needs to put or get from cache, it'll have the host address for that particular shard and will make its call to the appropriate host. These calls from service to cache host will be made using either TCP or UDP connections. If needed, we can dive deep into the pros and cons of using TCP vs UDP.</p>\n<p>Here're all the methods we've discussed for cache server discovery:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 50.68825910931174%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsSAAALEgHS3X78AAACRUlEQVQoz62P204TURiF5wV8C2PiK3irURMvvFJvuPEEHgii0QsTY0IiN4bQkIgB0SAhYqKC9CBGNNAgEDNtbdMTLUyn7bSFFpAeZnru9HPa1D6BK1nZe/3519prC81mk4be6LKFQ7WCP5klmMqyky6wnc4jZfKE9wooh0VDq9QaOhjeZoftu+EV+E9oFzMoVOol1uNWlqVZNhQb1UbFeL3GprLEivyBZD7CWvQzP2OLlGpFWjX0pk6jXqOcz1IxWNUK3WBh58hD7/w57r15QN/8eeK5EIX6PgMz/dwwPeKtf4i+Fw/pnbyNoga7xno6QWDyGaLpCXvmafa0Kmu7WivQweCnOwyNubk/34+c81DVi4wvT2FamMWz/5Fx6ywm2yv+lJMY5fhTSVGsZmmWNIr5nJFexiznOG2WWoFeBhbO8Hj6EoMLZ5Gyvk6HBtlamblwjky51NYt2OVF7s5c5eX6MHVjpne2vycK9PxQEHx5H6OjJ/BePMbI2El8qr+zopM0cq5tZNlWm23dwlJojuvDIzy3jRiBGnon8ZtS4MpyDCF6JDNluYl14jITX24RO4pSVoto1RoH7hUCTy+Q3rQYX2xQVDWSBzFE6RehlB9N08gXVKiWmPOlOPXeixDeChMMSfgkmeCWRCgYQo5EiO9mCHx9x1LPcbzm1yiGliMSSjxBJpUhldglGo0ZjJKIx3CGZRbdOwh2ux2LxYzNYsFqtbC6uorD4WjT6XLh8nhx/vZ0Z6JDRBTF9vlv1qLb5STgdvIXTIW9TSyoDnkAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Distributed Cache 8\"\n        title=\"Distributed Cache 8\"\n        src=\"/static/2aac6325e0d06157516c9527ac6e158f/1dda8/distributed-cache8.png\"\n        srcset=\"/static/2aac6325e0d06157516c9527ac6e158f/27f03/distributed-cache8.png 173w,\n/static/2aac6325e0d06157516c9527ac6e158f/376d0/distributed-cache8.png 345w,\n/static/2aac6325e0d06157516c9527ac6e158f/1dda8/distributed-cache8.png 690w,\n/static/2aac6325e0d06157516c9527ac6e158f/bcbcb/distributed-cache8.png 1035w,\n/static/2aac6325e0d06157516c9527ac6e158f/0787f/distributed-cache8.png 1235w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span> <a href=\"https://www.youtube.com/watch?v=iuqZvajTOyA&#x26;ab_channel=SystemDesignInterview\">Image Credit</a></p>\n<p>So far, we've handled our scalability and performance requirements. We've got an LRU cache algorithm that is performant and our lookups are fast. However, we've done nothing to make our system highly available: if a shard goes down, we don't have any backups to serve from meaning all cached data in that shard is lost.  </p>\n<h3 id=\"replication-to-achieve-high-availability\"><a href=\"#replication-to-achieve-high-availability\" aria-label=\"replication to achieve high availability permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Replication to Achieve High Availability</h3>\n<p>Types of replication models:</p>\n<ul>\n<li><strong>Probabilistic Protocols</strong></li>\n</ul>\n<p>These protocols include gossip, epidemic broadcast tress, bimodal multicast. <strong>These protocols are eventually consistent.</strong></p>\n<ul>\n<li><strong>Consensus Protocols</strong></li>\n</ul>\n<p>These protocols include 2 or 3 phase commit, paxos, raft and chain replication. <strong>These protocols tend to favor strong consistency.</strong></p>\n<p>To keep things simple, we'll use one of the three methods we already know: single leader, multi leader or leaderless replication. </p>\n<p>Single leader replication would imply that one of our cache servers would act as a leader and we'd have followers in different regions. All cache updates will be sent from this leader to its followers. If the leader fails, a failover process will kick in that'll promote one of the followers to a leader. All <code class=\"language-cpptext\">put</code> calls will go to the leader while <code class=\"language-cpptext\">get</code> calls can be handled by either the leader or the replica:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 32.229795520934765%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsSAAALEgHS3X78AAABgUlEQVQY022NS0sbARSF57+UQh8ru/IndCN250q6ScGN266kSAOi0kUwIGKLiCjik9o2tlgdNZOHk5hmkhBtYmysOsYYHONMxok0nc8xVXzQA+d+cDj3XoH/yLZtZ/zjtS+DmsM/f+16x6zZSEWLfbN2Z1c4r1UJ/p5nMTvFt9ww8eLSzdH7T25pvWQhvAvRpWhQrbB/UMCynGxTVWidfEbLUAOuARfumS6MSgXTPEPXDU5OyuiGQfXMZDanMbWlYelldksa3kSRNbWMZZxyrGlOX0cIp1d4OdLIq7HnvH7jo6c3xE4uw+52htxmmnQiznb2J0d7eR5/kHk4GCaf/8Xhgcpp6ZAjh6qqUigU6hS+h3286HtKk+cJze5m2jztpJIJUqlknRsOY9EIPyJrjK5EGRZlMokYc4EID7o/8tYnk00qhOUIiqIgLK+KvJ/10D/dg3emkxGfl0AgiCRJVw7gd+j3S6yHJKJBCdnx2NclHrnH6ZhYICgu8unzF0RR5AL9VJp+zi82PAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Distributed Cache 9\"\n        title=\"Distributed Cache 9\"\n        src=\"/static/e4b966349938fb531e5815f9638be373/1dda8/distributed-cache9.png\"\n        srcset=\"/static/e4b966349938fb531e5815f9638be373/27f03/distributed-cache9.png 173w,\n/static/e4b966349938fb531e5815f9638be373/376d0/distributed-cache9.png 345w,\n/static/e4b966349938fb531e5815f9638be373/1dda8/distributed-cache9.png 690w,\n/static/e4b966349938fb531e5815f9638be373/3d731/distributed-cache9.png 1027w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span> <a href=\"https://www.youtube.com/watch?v=iuqZvajTOyA&#x26;ab_channel=SystemDesignInterview\">Image Credit</a></p>\n<p>We'll perform our data replication asynchronously for better performance. We don't want to wait for all replicas to return acks before returning back to the client. </p>\n<p>Here's our entire system summarized:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 690px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 51.66757791142701%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsSAAALEgHS3X78AAABq0lEQVQoz4WSzUrDQBDH8wo+gFcv+gA+hxc9efLiSTx5qKgXoYr1oIgUxO8KfpSCInpRbIvQaIuh1lRsUaQqVGtLP5I2yW7+Jpu0Ji3iwrAzzO7Mf367HNUpTNN13TCw3VzU3s/e61hOV5gvFFUEXmRImpVrnnUuzh3+HlSp5Y+EP9C9JTLfKxTQtXaPnOxu6izLbcS8WOU92OHXcZYIg1Di6l5RKcRvGbsPBfB5CWKxDoX+NtYpdRk3eNCLgaNujCx5ML0YhkK01mFiFxXLGjh/GocvNRYThqdzXKYwJPqxl1rA/u0ezhPXoA6F5hVqdK0aKqP5Bj7rhMUtzg0ZjScBakaA8piAmsu0M0QHbI1QV04l1mhM6ecbXn3jeJobQ3Z2FN+HK+A2Y/Pw30xhlzG86mBoFjQ58gUFXw1q5B0K6zXIQhTSXQRS/BJKNglu6KDPZjiJmcWoi6Fmw89WDIbLKYNh9X+GRw8r2El6EeC3cRqPtBQ2v8RJToIvVUIoU0LwuYzj16rxpeB4ZWK/sLX/yZDY6oYvcugPZpk/wefRE0ijbA3Bmupt9gOZ1OPIvjyj0AAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Distributed Cache 10\"\n        title=\"Distributed Cache 10\"\n        src=\"/static/b49d5ebddafed9d0a2eebeeaac3ba2f7/1dda8/distributed-cache10.png\"\n        srcset=\"/static/b49d5ebddafed9d0a2eebeeaac3ba2f7/27f03/distributed-cache10.png 173w,\n/static/b49d5ebddafed9d0a2eebeeaac3ba2f7/376d0/distributed-cache10.png 345w,\n/static/b49d5ebddafed9d0a2eebeeaac3ba2f7/1dda8/distributed-cache10.png 690w,\n/static/b49d5ebddafed9d0a2eebeeaac3ba2f7/bcbcb/distributed-cache10.png 1035w,\n/static/b49d5ebddafed9d0a2eebeeaac3ba2f7/b4b06/distributed-cache10.png 1380w,\n/static/b49d5ebddafed9d0a2eebeeaac3ba2f7/51aa1/distributed-cache10.png 1829w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span> <a href=\"https://www.youtube.com/watch?v=iuqZvajTOyA&#x26;ab_channel=SystemDesignInterview\">Image Credit</a></p>\n<h3 id=\"useful-architectures\"><a href=\"#useful-architectures\" aria-label=\"useful architectures permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Useful architectures</h3>\n<ul>\n<li><a href=\"https://docs.aws.amazon.com/whitepapers/latest/best-practices-wordpress/reference-architecture.html\">WordPress on AWS</a></li>\n<li><a href=\"https://netflixtechblog.com/active-active-for-multi-regional-resiliency-c47719f6685b\">Netflix active-active</a></li>\n</ul>","timeToRead":29,"excerpt":"System Design Generating Unique IDs in a distributed Env Back of the envelope Estimation Storing Images Allowing users to chat Design Chat…","frontmatter":{"title":"Practical System Design","date":"2021-04-15T00:00:00.000Z","categories":["System Design"],"extract":"Practical system design","thumbnail":"/post-images/distributed-systems.png","tags":["Data system design"]},"fields":{"slug":"/practical-system-design","date":"April 15, 2021"}}},"pageContext":{"slug":"/practical-system-design","nexttitle":"DP Discussion Updated","nextslug":"/dp-discussion-updated","prevtitle":"C++ Standard input","prevslug":"/c-standard-input"}}}